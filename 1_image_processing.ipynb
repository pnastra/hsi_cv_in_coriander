{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d943a700",
   "metadata": {},
   "source": [
    "# 1. Data Acquisition & Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb9cf5",
   "metadata": {},
   "source": [
    "**Author**: Navavat Pipatsart, pnastranagant@gmail.com\n",
    "\n",
    "**language**: python\n",
    "\n",
    "**environemt**: jupyter notebook\n",
    "\n",
    "**Objective**: To perform data preprocessing using signal processing approach then save for **Part 2. Exploratory Data Analysis & Data Preparation**\n",
    "\n",
    "**Last modified date**: 2022-06-16\n",
    "\n",
    "**Modified issue**: \n",
    "- implement vc data\n",
    "- refactor path_to_black_references\n",
    "\n",
    "**status**: Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c6259",
   "metadata": {},
   "source": [
    "## Environmental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1be33",
   "metadata": {},
   "source": [
    "### 1.1. Miscellaneous Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import global library\n",
    "import numpy as np\n",
    "\n",
    "# System configuration\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e30a97",
   "metadata": {},
   "source": [
    "### 1.2. Main Configuration\n",
    "\n",
    "**NOTE**: This project datasets is located in *on-premise external harddisk*. Hence, path will be set to the located files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd59e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------\n",
    "# Define paths\n",
    "## On-premise paths\n",
    "parent_path = '/Volumes/phdbackup/backup/coriander_samples_data/' # define parent path to files\n",
    "path_to_black_references = 'black_references/'\n",
    "path_to_save = '/Volumes/phdbackup/backup/processed_data/preprocessed_data_20220616/' # define path to save files\n",
    "\n",
    "## On-cloud path\n",
    "parent_path_cloud = '/Users/pnastra/pnastranagant@gmail.com - Google Drive/My Drive/' # parent path to files in cloud\n",
    "path_to_wavelengths = parent_path_cloud + 'phd_codes/metadata/wavelengths.csv' # full path to full spectrum wavelengths profile\n",
    "\n",
    "# Define children path to files\n",
    "filenames_sample_dict = {\n",
    "    '2022_02_15_coriander_vb_d1/' : 'black_reference_laptop',\n",
    "    '2022_02_22_coriander_vb_d8/' : 'black_reference_laptop',\n",
    "    '2022_02_22_coriander_vbci_d8/' : 'black_reference_laptop',\n",
    "    '2022_06_08_coriander_vc_d1': 'black_reference_20220608',\n",
    "    '2022_06_15_coriander_vc_d8': 'black_reference_20220615',\n",
    "    '2022_06_15_coriander_vcci_d8': 'black_reference_20220615'\n",
    "    }\n",
    "\n",
    "# Define path to black references\n",
    "filenames_black_references_dict = {\n",
    "    '2022_02_03_coriander_vaci_d8/' : 'black_reference_laptop/capture/coriander__vaci_d8_s26_2022-02-03_08-57-56.raw',\n",
    "    '2022_02_15_coriander_vb_d1/' : 'black_reference_laptop/capture/coriander__vaci_d8_s26_2022-02-03_08-57-56.raw',\n",
    "    '2022_02_22_coriander_vb_d8/' : 'black_reference_laptop/capture/coriander__vaci_d8_s26_2022-02-03_08-57-56.raw',\n",
    "    '2022_02_22_coriander_vbci_d8/' : 'black_reference_laptop/capture/coriander__vaci_d8_s26_2022-02-03_08-57-56.raw',\n",
    "    '2022_06_08_coriander_vc_d1': 'black_reference_20220608/capture/sample__blackref__2022-06-08_03-05-50.raw',\n",
    "    '2022_06_15_coriander_vc_d8': 'black_reference_20220615/capture/coriander___blackref__2022-06-15_02-53-36.raw',\n",
    "    '2022_06_15_coriander_vcci_d8': 'black_reference_20220615/capture/coriander___blackref__2022-06-15_02-53-36.raw'\n",
    "    }\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# Image preprocessing variables\n",
    "wavelet = True # option to enable wavelet denoising\n",
    "median = True # option to enable median filtering\n",
    "triangle = True # option to enable triangle segmentation\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# Define miscellaneous variables\n",
    "save = True # Data saving option\n",
    "save_figure = True # Image saving option\n",
    "\n",
    "# Preload variables\n",
    "wavelengths = np.fromfile(file=path_to_wavelengths, sep=',') # load list of actual wavelengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257336a",
   "metadata": {},
   "source": [
    "## 2. Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d7a456",
   "metadata": {},
   "source": [
    "### 2.1. Data I/O Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to loading (image data & black reference)\n",
    "def load_image(path_to_file: str,\n",
    "               is_black_ref: bool):\n",
    "    \n",
    "    '''\n",
    "    Function to loading (image data & black reference)\n",
    "    steps:\n",
    "    1. Loading raw data from assigned 'path_to_file' -> cast data type as 'int16'. The loaded data has 3 axes i.e.\n",
    "     1.1. Length-axis: a spatial-domain with time-dependence size depending on time-usage while image acquistion\n",
    "     1.2. Width-axis: a spatial-domain with fixed size as 640\n",
    "     1.3. Spectral-axis: a spectral-domain with fixed size as 224 (full spectrum)\n",
    "    2. Reshape loaded data to dimensionality = (lenght, spectral, width, (length, 224, 640))\n",
    "    3. Swap axes from dimensionality = (lenght, spectral, width, (length, 224, 640)) => dimensionality = (length, width, spectral, (length, 640, 224)) for human intuition\n",
    "    4. If the loaded data as black reference option is enabled by assigning 'is_black_ref' = True. Slice only top row of length because it is constant in length-axis\n",
    "    5. Return output image as tensor/ hyperspectral cube\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    \n",
    "    print('begin to loading file from', path_to_file)\n",
    "        \n",
    "    image = np.fromfile(file=path_to_file, dtype='int16') # Load image data from file\n",
    "    image = image.reshape(-1,224,640) # Reshape => (lenght, spectral, width, (length, 224, 640))\n",
    "    image = image.swapaxes(1,2) # Swap axes from (lenght, spectral, width, (length, 224, 640)) => (length, width, spectral, (length, 640, 224)) for human intuition\n",
    "\n",
    "    print('loading image done \\n')\n",
    "    \n",
    "    # Black reference checker\n",
    "    if is_black_ref == True:\n",
    "        \n",
    "        image = image[0,...] # Slice black reference data as matrix (640, 224) <- assume black reference is equal in length-axis\n",
    "    \n",
    "        print('black reference has been transformed into matrix (width, spectral)')\n",
    "        print('loading black reference done')\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb032059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to saving prepared dataset to directory\n",
    "def save_dataset(data,\n",
    "                 dataname: str,\n",
    "                 path_to_save: str):\n",
    "    \n",
    "    '''\n",
    "    Function to saving prepared dataset to directory\n",
    "    Save dataset to assigned 'path_to_save' with naming by current date and assigned name\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    \n",
    "    print('begin to saving data to path: ', path_to_save)\n",
    "    print('begin to saving ', dataname)\n",
    "    \n",
    "    # Save dataset with date timestamp\n",
    "    np.save(file=(path_to_save + str(date.today()) + '_' + dataname),\n",
    "            arr=data) \n",
    "    \n",
    "    print('saving ', dataname , 'done')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3db63d",
   "metadata": {},
   "source": [
    "### 2.2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25184d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform PSNR calculation between 2 image tensors\n",
    "def calculate_psnr(original_image_tensor,\n",
    "                   processed_image_tensor):\n",
    "    \n",
    "    '''\n",
    "    Function to perform PSNR calculation between 2 image tensors\n",
    "    1. Loop through spectral-axis then calculate PSNR compare to input image matrix\n",
    "    2. Return output as image matrix and PSNR\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from skimage import metrics\n",
    "    \n",
    "    # Define collector\n",
    "    psnr_matrix_denoised = []\n",
    "    \n",
    "    # Loop through spectral-axis\n",
    "    for wavelength in range(original_image_tensor.shape[-1]):\n",
    "    \n",
    "        # Compute PSNR as an indication of image quality\n",
    "        temp = metrics.peak_signal_noise_ratio(image_true=original_image_tensor[...,wavelength], \n",
    "                                               image_test=processed_image_tensor[...,wavelength], \n",
    "                                               data_range=np.amax(original_image_tensor[...,wavelength]) - np.amin(original_image_tensor[...,wavelength]))\n",
    "        \n",
    "        psnr_matrix_denoised.append(temp) # Collect to collector\n",
    "        \n",
    "    return psnr_matrix_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387867a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract label from file name\n",
    "def extract_label(filename: str,\n",
    "                  label_type: str):\n",
    "    \n",
    "    '''\n",
    "    Function to extract label (y) from file name\n",
    "    for example:\n",
    "    file name = data__va_d1_s06_2022-01-27_04-27-39.raw\n",
    "    if 'label_type' = y: output is va_d1\n",
    "    if 'label_type' = number: output is 06\n",
    "    '''\n",
    "    \n",
    "    # Label_type y checker\n",
    "    if label_type == 'y':\n",
    "        \n",
    "#         label_extracted = filename.split(\"__\")[-1].split(\"_s\")[0] # Assign label -> cut some unneceasary. y should obtain likes 'va_d1'\n",
    "        label_extracted = filename.split(\"coriander_\")[-1].split(\"/\")[0] # Assign label -> cut some unneceasary. y should obtain likes 'va_d1'\n",
    "    \n",
    "    # Label_type number checker\n",
    "    elif label_type == 'number':\n",
    "        \n",
    "        label_extracted = filename.split('_s')[-1].split('_')[0] # Assign label -> cut some unneceasary. number should obtain likes '06'\n",
    "    \n",
    "    return label_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a5d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to randomly select wavelengths from given filenames\n",
    "def samplier(path_to_files: str,\n",
    "             sample_size: int):\n",
    "    \n",
    "    '''\n",
    "    Function to randomly select wavelengths from given filenames\n",
    "    steps:\n",
    "    1. Construct list of filenames by excluding non-image file\n",
    "    2. Randomly select certain filenames from filenames list\n",
    "    3. Extract selected filenames list from full filename\n",
    "    4. Ascending sort filenames by sample number\n",
    "    5. Return output as list\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import os\n",
    "    import random\n",
    "    \n",
    "    filenames = [filename for filename in os.listdir(path_to_files) if not filename.startswith('.')] # Extract filenames\n",
    "    sampled_filenames = random.sample(filenames, sample_size) # Sampling index from filenames\n",
    "    samples = [int(sample.split('_s')[-1].split('_')[0]) for sample in sampled_filenames] # Extract sample numbers\n",
    "    samples = sorted(samples) # Sort the numbers\n",
    "    \n",
    "    print('chosen sample number:', samples)\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate averaged reflectance over spatial domain (width & length axises)\n",
    "def calculate_average(data,\n",
    "                      axis):\n",
    "    \n",
    "    '''\n",
    "    Function to calculate averaged reflectance over spatial domain (width & length axises) then return output as signle averaged value\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    \n",
    "    # Calculate average along spectral-axis of sample image data\n",
    "    data_averaged = np.mean(data, axis=axis)\n",
    "    \n",
    "    return data_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0cb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to print iterations progress (imported from open-source)\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    \n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    \n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    \n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        \n",
    "        print()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_hours(time_usage):\n",
    "    \n",
    "    print('to time usage in hours =', time_usage / (60 * 60))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e2f7aa",
   "metadata": {},
   "source": [
    "### 2.3. Image Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148abaf",
   "metadata": {},
   "source": [
    "**Calibration function for reflectance of corrected hyperspectral image**\n",
    "\n",
    "$ R_{c} = \\frac{R_{r} - B}{W - B} \\times100\\%  $,\n",
    "\n",
    "where:\n",
    "1. $ R_{r} $: reflectance of the raw hyperspectral image\n",
    "2. B: dark current image (~0% reflectance)\n",
    "3. W: white reference image (~99.9% reflectance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform calibration of an input image\n",
    "def image_calibrater(image_tensor,\n",
    "                     black_ref_matrix):\n",
    "    \n",
    "    '''\n",
    "    function to perform calibration of an input image\n",
    "    steps:\n",
    "    1. find white reference by assuming as the maximum reflectance wavelength-wised of the assigned tensor\n",
    "    2. calculate raw reflectance (R) - black reference (B) whole image wavelength-wised of the assigned tensor\n",
    "    3. calculate white reference (W) - black reference (B) top length-axis wavelength-wised of the assigned tensor\n",
    "    4. calculate calibration by performing (R-B)/(W-B)\n",
    "    5. return output as tensor\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    \n",
    "    print('begin to perform calibration')\n",
    "    \n",
    "    # White reference preparation\n",
    "    white_ref_vector = np.amax(image_tensor, axis= (0,1)) # Max argument as vector (224,) along spectral axis -> assign to being white reference\n",
    "    \n",
    "    # Calibration preparation\n",
    "    r_minus_b = np.subtract(image_tensor, black_ref_matrix) # = reflectance - black reference (length, 640, 224)\n",
    "    w_minus_b = np.subtract(white_ref_vector, black_ref_matrix) # = white reference - black reference (640, 224)\n",
    "    image_tensor_calibrated = np.divide(r_minus_b, w_minus_b[np.newaxis, :, :]) # Perform calibration\n",
    "    \n",
    "    print('calibration done')\n",
    "    \n",
    "    return image_tensor_calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform image resizing image data with specific size using interpolation\n",
    "def resize_image(image_tensor,\n",
    "                  output_size: int):\n",
    "    \n",
    "    '''\n",
    "    Function to perform image resizing image data with specific size using interpolation as return outout as image matrix\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from skimage import transform\n",
    "    \n",
    "    print('begin to perform local mean resizing')\n",
    "    \n",
    "    # Assign collector\n",
    "    image_tensor_resized = []\n",
    "    \n",
    "    # Loop through spectral-axis\n",
    "    for wavelength in range(image_tensor.shape[-1]):\n",
    "    \n",
    "        # Perform resizing image\n",
    "        temp = transform.resize_local_mean(image=image_tensor[...,wavelength], \n",
    "                                           output_shape=(output_size, output_size))\n",
    "        \n",
    "        image_tensor_resized.append(temp) # Collect to collector\n",
    "        \n",
    "    image_tensor_resized = np.stack(image_tensor_resized, axis=-1) # Reformat list => array\n",
    "    \n",
    "    print('local mean resizing done')\n",
    "    \n",
    "    return image_tensor_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform periodic-noise reduction in frequency-domain of the image using difference of Gaussian algorithm\n",
    "def filter_gaussians(image_matrix):\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from skimage import filters\n",
    "    from skimage import metrics\n",
    "    \n",
    "    '''\n",
    "    Function to perform periodic-noise reduction image filtering in frequency-domain using difference of Gaussian algorithm\n",
    "    1. Filter image using difference of Gaussians algorithm\n",
    "    2. Improve ROI using window image\n",
    "    3. Calculate PSNR compare to input image matrix\n",
    "    4. Return output as image matrix and PSNR\n",
    "    '''\n",
    "    \n",
    "    # Filter image\n",
    "    image_pre_filtered = filters.difference_of_gaussians(image=image_matrix, \n",
    "                                                         low_sigma=2, \n",
    "                                                         high_sigma=50)\n",
    "    \n",
    "    image_filtered = image_pre_filtered * filters.window('hann', image_matrix.shape) # Window image to improve FFT\n",
    "\n",
    "    # Compute PSNR as an indication of image quality\n",
    "    psnr_filtered = metrics.peak_signal_noise_ratio(image_matrix, image_filtered, data_range=np.amax(image_matrix)-np.amin(image_matrix))\n",
    "    \n",
    "    return image_filtered, psnr_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform wavelet denoising on an image using BayesShrink algorithm with Daubechies wavelet\n",
    "def denoiser_wavelet(image_tensor):\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from skimage import restoration\n",
    "    \n",
    "    '''\n",
    "    Function to perform wavelet denoising on an image using BayesShrink algorithm with Daubechies wavelet\n",
    "    1. Denoise image using wavelet denoising\n",
    "    2. Calculate PSNR compare to input image matrix\n",
    "    3. Return output as image matrix and PSNR\n",
    "    '''\n",
    "    \n",
    "    print('begin to perform wavelet denoising')\n",
    "    \n",
    "    # Denoising image\n",
    "    image_tensor_denoised = restoration.denoise_wavelet(image=image_tensor,\n",
    "                                                         wavelet='db2', \n",
    "                                                         mode='soft', \n",
    "                                                         method='BayesShrink',\n",
    "                                                         channel_axis=-1)\n",
    "    \n",
    "    # Calculate PSNR\n",
    "    psnr_matrix_denoised = calculate_psnr(original_image_tensor=image_tensor,\n",
    "                                          processed_image_tensor=image_tensor_denoised)\n",
    "    \n",
    "    print('wavelet denoising done')\n",
    "\n",
    "    return image_tensor_denoised, psnr_matrix_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform Gaussian, random, and salt and pepper-noise reduction image filtering using non-linear median algorithm\n",
    "def filter_median(image_tensor):\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from skimage import filters\n",
    "    from skimage import morphology\n",
    "    \n",
    "    '''\n",
    "    Function to perform Gaussian, random, and salt and pepper-noise reduction image filtering using non-linear median algorithm\n",
    "    1. Define kernel/footprint for filering\n",
    "    2. Filter image using non-linear median algorithm\n",
    "    3. Calculate PSNR compare to input image matrix\n",
    "    4. Return output as image matrix and PSNR\n",
    "    '''\n",
    "    \n",
    "    print('begin to perform median filtering')\n",
    "    \n",
    "    kernel_size = 3\n",
    "    footprint = np.ones((kernel_size, kernel_size, image_tensor.shape[-1]))\n",
    "    \n",
    "    # Filter image\n",
    "    image_tensor_filtered = filters.median(image=image_tensor,\n",
    "                                           footprint=footprint)\n",
    "\n",
    "    # Calculate PSNR\n",
    "    psnr_matrix_filtered = calculate_psnr(original_image_tensor=image_tensor,\n",
    "                                          processed_image_tensor=image_tensor_filtered)\n",
    "    \n",
    "    print('median filtering done')\n",
    "    \n",
    "    return image_tensor_filtered, psnr_matrix_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36487b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform calculate threshold value using triangle algorithm then construct mask and apply to image \n",
    "def thresholder_triangle(image_tensor):\n",
    "    \n",
    "    '''\n",
    "    Function to perform calculate threshold value using triangle algorithm then construct mask and apply to image \n",
    "    1. Calculate threshold value using triangle algorithm for lesser noise-spectrum image -> assume as representator\n",
    "    2. Construct boolean mask\n",
    "    3. Loop through spectral-domain, create zeros-array shape like image matrix\n",
    "    4. Apply mask to image matrix\n",
    "    5. Collect to collector and reformat collector from list => numpy array\n",
    "    6. Calculate PSNR\n",
    "    7. Return output\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from skimage import filters\n",
    "        \n",
    "    print('begin to perform triangle thresholding')\n",
    "    \n",
    "    threshold_value = filters.threshold_triangle(image=image_tensor[...,50]) # Calculate threshold value using triangle algorithm\n",
    "    mask = image_tensor[...,50] > threshold_value # Construct boolean mask\n",
    "\n",
    "    # Assign collector\n",
    "    image_tensor_thresholded = []\n",
    "    \n",
    "    # Loop through spectral-domain\n",
    "    for wavelength in range(image_tensor.shape[-1]):\n",
    "        \n",
    "        temp = np.zeros_like(image_tensor[..., wavelength]) # Create zeros-array shape like image matrix\n",
    "        temp[mask] = image_tensor[..., wavelength][mask] # Apply mask to image matrix\n",
    "        image_tensor_thresholded.append(temp) # Collect to collector\n",
    "       \n",
    "    image_tensor_thresholded = np.stack(arrays=image_tensor_thresholded, axis=-1) # Collect to collector\n",
    "    \n",
    "    # Calculate PSNR\n",
    "    psnr_matrix_thresholded = calculate_psnr(original_image_tensor=image_tensor,\n",
    "                                             processed_image_tensor=image_tensor_thresholded)\n",
    "    \n",
    "    print('triangle thresholding done')\n",
    "    \n",
    "    return image_tensor_thresholded, psnr_matrix_thresholded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33f9fa",
   "metadata": {},
   "source": [
    "### 2.4. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to comparative visualize between 2 images\n",
    "def viz_compare(image_1,\n",
    "                image_2,\n",
    "                title_1: str,\n",
    "                title_2: str,\n",
    "                save: bool,\n",
    "                figurename: str,\n",
    "                path_to_save: str):\n",
    "    \n",
    "    '''\n",
    "    Dunction to comparative visualize between 2 images\n",
    "    steps:\n",
    "    1. Create empty figure for drawing sub-figures of images\n",
    "    2. Draw image 1\n",
    "    3. Draw image 2\n",
    "    4. Consider save figure option is enabled by 'save' = True. Save figure to assigned 'path_to_save' with naming by current date and assigned name\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    from datetime import date\n",
    "    from matplotlib import pyplot as plt # Figure drawing\n",
    "    from scipy import ndimage as ndimage # Image rotation\n",
    "    \n",
    "    # Figure configuration\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 8), sharex=True, sharey=True)\n",
    "    fontsize = 16\n",
    "    fig.suptitle(figurename, fontsize=fontsize)\n",
    "\n",
    "    # Draw 1st image\n",
    "    ax1.imshow(ndimage.rotate(input=image_1, angle=180))\n",
    "    ax1.set_title(title_1, fontsize=fontsize) # Set image title\n",
    "    ax1.axis(\"off\") # Disable axes label\n",
    "\n",
    "     # Draw 2nd image\n",
    "    ax2.imshow(ndimage.rotate(input=image_2, angle=180))\n",
    "    ax2.set_title(title_2, fontsize=fontsize) # Set image title\n",
    "    ax2.axis(\"off\") # Disable axes label\n",
    "    \n",
    "    # Decoration\n",
    "    plt.margins(0, 0)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurename + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurename, 'done') \n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to comparative visualize among spectral-axis\n",
    "def viz_spectral(data,\n",
    "                 indices_list: list,\n",
    "                 wavelengths: list,\n",
    "                 save: bool,\n",
    "                 figurename: str, \n",
    "                 path_to_save: str):\n",
    "    \n",
    "    '''\n",
    "    Function to comparative visualize among spectral-axis\n",
    "    steps:\n",
    "    1. Loop through assigned wavelengt for drawing 9 images, then draw image\n",
    "    2. Consider save figure option checker; if save == True: figure\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    from matplotlib import pyplot as plt # Figure drawing\n",
    "    from scipy import ndimage as ndimage # Image rotation\n",
    "    \n",
    "    # Figure configuratio\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(10, 8), sharex=True, sharey=True)\n",
    "    fontsize = '16' # Define fontsize\n",
    "    fig.suptitle(figurename, fontsize=fontsize)\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    # Loop through assigned wavelengt for drawing 9 images\n",
    "    for index, wavelength in enumerate(indices_list):\n",
    "        \n",
    "        # Draw image\n",
    "        axs[index].imshow(ndimage.rotate(input=data[...,wavelength], angle=180), aspect='auto') # draw image\n",
    "        axs[index].set_title('\\u03BB = ' + str(wavelengths[wavelength]) + ' nm', fontsize=fontsize) # Define image title\n",
    "        axs[index].axis(\"off\") # Disable axes\n",
    "    \n",
    "    # Decoration\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurename + '_' + str(date.today()) + '.png') # save figure\n",
    "        \n",
    "        print('save figure:', figurename, 'done')        \n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97394c59",
   "metadata": {},
   "source": [
    "### 2.5. Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main function to execute pipeline of defined functions\n",
    "def main(parent_path=parent_path,\n",
    "         path_to_black_references=path_to_black_references,\n",
    "         path_to_save=path_to_save,\n",
    "         parent_path_cloud=parent_path_cloud,\n",
    "         wavelengths=wavelengths,\n",
    "         filenames_sample_dict=filenames_sample_dict,\n",
    "         filenames_black_references_dict=filenames_black_references_dict,\n",
    "         save=save,\n",
    "         wavelet=wavelet,\n",
    "         median=median,\n",
    "         triangle=triangle\n",
    "         ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Main function to execute pipeline of defined functions\n",
    "    steps:\n",
    "    1. Define necessary metadata\n",
    "    2. Define collectors and load black reference\n",
    "    3. Extract sample number\n",
    "    4. Perform load sample data, calibrate, and calculate averaged refrectance of sample data\n",
    "    5. Visualize calibrated sample data\n",
    "    6. Perform data preprocessing using image processing approach, collect PSNR ,and visualize preprocessed sample data\n",
    "    7. Collect to collectors\n",
    "    8. Save preprocessed data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import os\n",
    "    import time\n",
    "    import random\n",
    "    import numpy as np\n",
    "    \n",
    "    start_time_total = time.time() # Memory starting time\n",
    "    \n",
    "    # Define list of wavelenght indices to comparative visualization\n",
    "    indices_list = np.arange(0, len(wavelengths), len(wavelengths) // 9)\n",
    "    indices_list = np.delete(indices_list, len(indices_list) // 2)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # 1. Define necessary metadata\n",
    "    # Loop through files for define metadata of each treatment\n",
    "    for folder in filenames_sample_dict.keys():\n",
    "\n",
    "        print('begin to execute main function to', folder)\n",
    "\n",
    "        path_to_files = parent_path + folder # Concatenate path name\n",
    "        \n",
    "        # Execute function to extract label from file name #!\n",
    "        extracted_y = extract_label(filename=folder,\n",
    "                                    label_type='y')\n",
    "\n",
    "        print('Dataname is: ', extracted_y)\n",
    "\n",
    "        # Flip option checker\n",
    "        if folder in ['2022_06_08_coriander_vc_d1', '2022_06_15_coriander_vc_d8', '2022_06_15_coriander_vcci_d8']:\n",
    "            \n",
    "            flip = True # Enable vertically flip to images\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            flip = False # Disable vertically flip to images\n",
    "            \n",
    "        # --------------------------------------------------------------------------------------------------------\n",
    "        # 2. Define collectors and load black reference\n",
    "        \n",
    "        print('begin to loading and preprocessing')\n",
    "        print('begin to loading black reference')\n",
    "\n",
    "        start_time = time.time() # Memory starting time\n",
    "\n",
    "        # Assign global collectors\n",
    "        X = [] # Image variable data collector\n",
    "        X_wavelet = []\n",
    "        X_median = []\n",
    "        X_triangle = []\n",
    "        psnr_tensor_wavelet = []\n",
    "        psnr_tensor_median = []\n",
    "        psnr_tensor_triangle = []\n",
    "        y = [] # Image label/output collector\n",
    "        reflectances_averaged = [] # Averaged reflectance collector\n",
    "        number = 0 # Counter number of data collector\n",
    "        \n",
    "        path_to_black_reference = parent_path + path_to_black_references + filenames_black_references_dict[folder]\n",
    "        print('path_to_black_reference ===>', path_to_black_reference) #!\n",
    "        \n",
    "        # Execute function to loading black reference\n",
    "        black_ref_matrix = load_image(path_to_file=path_to_black_reference,\n",
    "                                      is_black_ref=True)\n",
    "                \n",
    "        print('begin to loading raw sample data')\n",
    "\n",
    "        # Iterate through directories\n",
    "        for subdir, dirs, files in os.walk(path_to_files):\n",
    "\n",
    "            # Interate through files \"inside path to files\"\n",
    "            for file in files:\n",
    "\n",
    "                # .raw format checker\n",
    "                if file.endswith('.raw'):\n",
    "\n",
    "                    # --------------------------------------------------------------------------------------------------------\n",
    "                    # 3. Extract sample number\n",
    "                    \n",
    "                    # Execute function to extract number from file name\n",
    "                    sample_number = extract_label(filename=file,\n",
    "                                                  label_type='number')\n",
    "\n",
    "                    print('sample number: ', sample_number)\n",
    "                    \n",
    "                    # --------------------------------------------------------------------------------------------------------\n",
    "                    # 4. Perform load sample data, calibrate, and calculate averaged refrectance of sample data\n",
    "\n",
    "                    # Execute function to loading image data\n",
    "                    image_tensor = load_image(path_to_file=os.path.join(subdir, file),\n",
    "                                              is_black_ref=False)\n",
    "                    \n",
    "                    # Vertically flip option checker\n",
    "                    if flip == True:\n",
    "                        \n",
    "                        image_tensor = np.flip(image_tensor, axis=0) # Vertically flip images\n",
    "                    \n",
    "                    # Slice image tensor to preventing \"label tag\" to compete \"calibration bar\" in calibration\n",
    "                    image_tensor = image_tensor[500:, ...]                   \n",
    "\n",
    "                    # Execute function to perform calibration of an input image\n",
    "                    image_tensor_calibrated = image_calibrater(image_tensor=image_tensor,\n",
    "                                                               black_ref_matrix=black_ref_matrix)\n",
    "                    \n",
    "                    # Execute function to calculate averaged reflectance over spatial domain (width & length axises)\n",
    "                    reflectance_averaged = calculate_average(data=image_tensor_calibrated,\n",
    "                                                                   axis=(0,1))\n",
    "            \n",
    "                    # --------------------------------------------------------------------------------------------------------\n",
    "                    # 5. Visualize calibrated sample data\n",
    "                    \n",
    "                    # Execute function to comparative visualize among spectral-axis\n",
    "                    figurename='Calibrated images of ' + extracted_y + '_' + sample_number\n",
    "\n",
    "                    viz_spectral(data=image_tensor_calibrated,\n",
    "                                 indices_list=indices_list,\n",
    "                                 wavelengths=wavelengths,\n",
    "                                 save=save_figure,\n",
    "                                 figurename=figurename, \n",
    "                                 path_to_save=path_to_save)\n",
    "\n",
    "                    # --------------------------------------------------------------------------------------------------------\n",
    "                    # 6. Perform data preprocessing using image processing approach, collect PSNR ,and visualize preprocessed sample data\n",
    "                    \n",
    "                    # Execute function to perform image resizing image data with specific size using interpolation\n",
    "                    image_tensor_preprocessed = resize_image(image_tensor=image_tensor_calibrated,\n",
    "                                                             output_size=128)\n",
    "\n",
    "                    # Execute function to comparative visualize among spectral-axis\n",
    "                    figurename='Resized images of ' + extracted_y + '_' + sample_number\n",
    "\n",
    "                    viz_spectral(data=image_tensor_preprocessed,\n",
    "                                 indices_list=indices_list,\n",
    "                                 wavelengths=wavelengths,\n",
    "                                 save=save_figure,\n",
    "                                 figurename=figurename, \n",
    "                                 path_to_save=path_to_save)\n",
    "\n",
    "                    del image_tensor # Remove unused raw image data for saving memory\n",
    "                    del image_tensor_calibrated # Remove unused raw image data for saving memory\n",
    "\n",
    "                    print('begin to perform image processing')\n",
    "\n",
    "                    # Option to enable wavelet denoising checker\n",
    "                    if wavelet == True:\n",
    "                    \n",
    "                        # Execute function to perform wavelet denoising on an image using BayesShrink algorithm with Daubechies wavelet\n",
    "                        image_tensor_preprocessed, psnr_matrix_wavelet = denoiser_wavelet(image_tensor=image_tensor_preprocessed)\n",
    "                \n",
    "                        X_wavelet.append(image_tensor_preprocessed) # Collect preprocessed data to collector  \n",
    "                        psnr_tensor_wavelet.append(psnr_matrix_wavelet) # Collect PSNR to collector  \n",
    "\n",
    "                        # Execute function to comparative visualize among spectral-axis\n",
    "                        figurename='Wavelet denoised images of ' + extracted_y + '_' + sample_number                        \n",
    "                        \n",
    "                        viz_spectral(data=image_tensor_preprocessed,\n",
    "                                     indices_list=indices_list,\n",
    "                                     wavelengths=wavelengths, \n",
    "                                     figurename=figurename,\n",
    "                                     save=save_figure,\n",
    "                                     path_to_save=path_to_save)\n",
    "                    \n",
    "                    # Option to enable median filtering checker\n",
    "                    if median == True:\n",
    "                        \n",
    "                        # Execute function to perform Gaussian, random, and salt and pepper-noise reduction image filtering using non-linear median algorithm\n",
    "                        image_tensor_preprocessed, psnr_matrix_median = filter_median(image_tensor=image_tensor_preprocessed)\n",
    "\n",
    "                        X_median.append(image_tensor_preprocessed) # Collect preprocessed data to collector\n",
    "                        psnr_tensor_median.append(psnr_matrix_median) # Collect PSNR to collector\n",
    "                        \n",
    "                    # Execute function to comparative visualize among spectral-axis\n",
    "                    figurename='Median filtered images of ' + extracted_y + '_' + sample_number                        \n",
    "\n",
    "                    viz_spectral(data=image_tensor_preprocessed,\n",
    "                                 indices_list=indices_list,\n",
    "                                 wavelengths=wavelengths, \n",
    "                                 figurename=figurename,\n",
    "                                 save=save_figure,\n",
    "                                 path_to_save=path_to_save)                        \n",
    "                        \n",
    "                    # Option to enable triangle segmentation checker\n",
    "                    if triangle == True :\n",
    "                        \n",
    "                        # Execute function to perform calculate threshold value using triangle algorithm then construct mask and apply to image\n",
    "                        image_tensor_preprocessed, psnr_matrix_triangle = thresholder_triangle(image_tensor=image_tensor_preprocessed)\n",
    "\n",
    "                        X_triangle.append(image_tensor_preprocessed) # Collect preprocessed data to collector\n",
    "                        psnr_tensor_triangle.append(psnr_matrix_triangle) # Collect PSNR to collector\n",
    "\n",
    "                        # Execute function to comparative visualize among spectral-axis\n",
    "                        figurename='Triangle threshold images of ' + extracted_y + '_' + sample_number                        \n",
    "                        \n",
    "                        viz_spectral(data=image_tensor_preprocessed,\n",
    "                                     indices_list=indices_list,\n",
    "                                     wavelengths=wavelengths, \n",
    "                                     figurename=figurename,\n",
    "                                     save=save_figure,\n",
    "                                     path_to_save=path_to_save)                        \n",
    "                        \n",
    "                    # --------------------------------------------------------------------------------------------------------\n",
    "                    # 7. Collect to collectors\n",
    "                    # Collect to global collectors\n",
    "                    y.append(extracted_y) # convert to array is not required\n",
    "                    reflectances_averaged.append(reflectance_averaged)\n",
    "                    number += 1 # iterate number of loaded data\n",
    "\n",
    "                    # Show progress bar\n",
    "                    printProgressBar(1, len(os.listdir(path_to_files)), prefix = 'Progress:', suffix = 'Complete', length = 50)    \n",
    "\n",
    "                    print('------------------------------------------------------------------------------------------ \\n')\n",
    "\n",
    "        # Reformat global collectors\n",
    "        X_wavelet = np.stack(X_wavelet, axis=0)\n",
    "        X_median = np.stack(X_median, axis=0)\n",
    "        X_triangle = np.stack(X_triangle, axis=0)\n",
    "        \n",
    "        reflectances_averaged = np.concatenate(reflectances_averaged, axis=0) # Transform list => numpy ndarray type\n",
    "        reflectances_averaged = reflectances_averaged.reshape(-1, 224) # Reshape to (number of samples, 224)\n",
    "\n",
    "        # Option to enable wavelet denoising checker\n",
    "        if wavelet == True:\n",
    "            \n",
    "            psnr_tensor_wavelet = np.stack(psnr_tensor_wavelet, axis=0) # Convert list => numpy ndarray type\n",
    "        \n",
    "        # Option to enable median filtering checker\n",
    "        if median == True:\n",
    "                \n",
    "            psnr_tensor_median = np.stack(psnr_tensor_median, axis=0) # Convert list => numpy ndarray type\n",
    "         \n",
    "        # Option to enable triangle segmentation checker\n",
    "        if triangle == True :\n",
    "            \n",
    "            psnr_tensor_triangle = np.stack(psnr_tensor_triangle, axis=0) # Convert list => numpy ndarray type\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------------------\n",
    "        # 8. Save preprocessed data\n",
    "        # Save option checker\n",
    "        if save == True: \n",
    "            \n",
    "            # Execute function to saving processed data\n",
    "            save_dataset(data=y,\n",
    "                         dataname='y_' + extracted_y,\n",
    "                         path_to_save=path_to_save)\n",
    "            \n",
    "            save_dataset(data=reflectances_averaged,\n",
    "                         dataname='reflectances_averaged_' + extracted_y,\n",
    "                         path_to_save=path_to_save)\n",
    "\n",
    "            # Option to enable wavelet denoising checker\n",
    "            if wavelet == True:\n",
    "            \n",
    "                save_dataset(data=X_wavelet,\n",
    "                             dataname='X_wavelet_' + extracted_y,\n",
    "                             path_to_save=path_to_save)\n",
    "            \n",
    "                save_dataset(data=psnr_tensor_wavelet,\n",
    "                             dataname='psnr_tensor_wavelet_' + extracted_y,\n",
    "                             path_to_save=path_to_save)\n",
    "\n",
    "            # Option to enable median filtering checker\n",
    "            if median == True:\n",
    "\n",
    "                save_dataset(data=X_median,\n",
    "                             dataname='X_median_' + extracted_y,\n",
    "                             path_to_save=path_to_save)\n",
    "                \n",
    "                save_dataset(data=psnr_tensor_median,\n",
    "                             dataname='psnr_median_' + extracted_y,\n",
    "                             path_to_save=path_to_save)\n",
    "\n",
    "            # Option to enable triangle segmentation checker\n",
    "            if triangle == True :\n",
    "\n",
    "                save_dataset(data=X_triangle,\n",
    "                             dataname='X_triangle_' + extracted_y,\n",
    "                             path_to_save=path_to_save)                \n",
    "                \n",
    "                save_dataset(data=psnr_tensor_triangle,\n",
    "                             dataname='psnr_tensor_triangle_' + extracted_y,\n",
    "                             path_to_save=path_to_save)\n",
    "\n",
    "        end_time = time.time() # Memory ending time\n",
    "\n",
    "        print('\\n')\n",
    "        print('loading and preprocessing data from', path_to_files,'done')\n",
    "        print('summary:')\n",
    "        print('data has been saved to', path_to_save )\n",
    "        print(number, 'files have been processed this time')\n",
    "        print('execution time:', end_time - start_time, 'seconds \\n') # calculate time usage\n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------------------------- \\n')\n",
    "\n",
    "    end_time_total = time.time() # Memory ending time\n",
    "    time_usage_total = end_time_total - start_time_total # Calculate time usage\n",
    "    \n",
    "    print('\\n')\n",
    "    print('total_execution time:', time_usage_total, 'seconds \\n')\n",
    "    \n",
    "    convert_to_hours(time_usage=time_usage_total) # Convert time usage to hour unit\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee7e120",
   "metadata": {},
   "source": [
    "## Execute main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2379be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f781ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf36c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
