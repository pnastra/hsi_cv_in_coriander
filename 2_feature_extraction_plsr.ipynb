{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b82ca8",
   "metadata": {
    "id": "f2b82ca8"
   },
   "source": [
    "# Part 2. Exploratory Data Analysis & Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11bab46",
   "metadata": {
    "id": "e11bab46"
   },
   "source": [
    "**Author**: Navavat Pipatsart, pnastranagant@gmail.com\n",
    "\n",
    "**language**: python\n",
    "\n",
    "**environemt**: jupyter notebook\n",
    "\n",
    "**Objective**: Explore pre-processed dataset from **Part 1. Data Acquisition & Data Preprocessing** using *Exploratory Data Analysis (EDA)* and prepare dataset via *Data Preparation* and *Feature Extraction* for further **3. Data Training and Model Evaluation**.\n",
    "\n",
    "**Last modified date**: 2022-06-23\n",
    "\n",
    "**Modified issue**: \n",
    "\n",
    "- Improve full spectrum data\n",
    "\n",
    "**status**: Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42bcd1",
   "metadata": {
    "id": "2c42bcd1"
   },
   "source": [
    "## 1. Environmental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad2360",
   "metadata": {
    "id": "e2ad2360"
   },
   "source": [
    "### 1.1. Miscellaneous Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c1ebf",
   "metadata": {
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1659173829554,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "301c1ebf"
   },
   "outputs": [],
   "source": [
    "# Import global libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# System configuration\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a0499",
   "metadata": {
    "id": "597a0499"
   },
   "source": [
    "### 1.2. Main Configuration\n",
    "\n",
    "**NOTE**: This project datasets is located in *on-premise external harddisk*. Hence, path will be set to the located files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ab43e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "executionInfo": {
     "elapsed": 874,
     "status": "error",
     "timestamp": 1659173830423,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "220ab43e",
    "outputId": "e63365aa-d083-43be-e0fd-b8f70584087d"
   },
   "outputs": [],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# Define filenames\n",
    "# !!! priority recheck\n",
    "date_preprocessed = '2022-06-16' \n",
    "\n",
    "# !!! priority recheck\n",
    "process_final = 'triangle'\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# Define paths\n",
    "## On-premise paths\n",
    "parent_path = '/Volumes/phdbackup/backup/processed_data/' # Parent path to pre-processed files and path to save\n",
    "\n",
    "# !!! priority recheck\n",
    "children_path_to_files = 'preprocessed_data_20220616/' # Children path to pre-processed files\n",
    "\n",
    "# !!! priority recheck\n",
    "children_path_to_save = 'prepared_data_20220623/' # Children path to save\n",
    "\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "path_to_files = parent_path + children_path_to_files # Full path to files\n",
    "path_to_save = '/Users/pnastra/OneDrive - Mahidol University/phd_thesis/thesis_results/preprocessing/' # Full path to save\n",
    "\n",
    "## On-cloud path\n",
    "parent_path_cloud = '/Users/pnastra/pnastranagant@gmail.com - Google Drive/My Drive/' # Parent path to files in cloud\n",
    "path_to_wavelengths = parent_path_cloud + 'phd_codes/metadata/wavelengths.csv' # Full path to full spectrum wavelengths profile\n",
    "path_to_wavelengths_trimmed = parent_path_cloud + 'phd_codes/metadata/wavelengths_trimmed.csv' # Full path to trimmed wavelengths from wavelength selection profile\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "## Variables, a.k.a. X\n",
    "filenames_X = [\n",
    "               date_preprocessed + '_X_' + process_final + '_vb_d1.npy', # Variety B, Treatment: Fresh\n",
    "               date_preprocessed + '_X_' + process_final + '_vb_d8.npy', # Variety B, Treatment: Deterioration\n",
    "               date_preprocessed + '_X_' + process_final + '_vbci_d8.npy', # Variety B, Treatment: Chilling Injury-induced\n",
    "               date_preprocessed + '_X_' + process_final + '_vc_d1.npy',\n",
    "               date_preprocessed + '_X_' + process_final + '_vc_d8.npy',\n",
    "               date_preprocessed + '_X_' + process_final + '_vcci_d8.npy'\n",
    "              ]\n",
    "\n",
    "## Labels, a.k.a. y\n",
    "filenames_y = [\n",
    "               date_preprocessed + '_y_vb_d1.npy', # Variety B, Treatment: Fresh\n",
    "               date_preprocessed + '_y_vb_d8.npy', # Variety B, Treatment: Deterioration\n",
    "               date_preprocessed + '_y_vbci_d8.npy', # Variety B, Treatment: Chilling Injury-induced\n",
    "               date_preprocessed + '_y_vc_d1.npy',\n",
    "               date_preprocessed + '_y_vc_d8.npy',\n",
    "               date_preprocessed + '_y_vcci_d8.npy'\n",
    "              ]\n",
    "\n",
    "\n",
    "## Calibrated averaged reflectances\n",
    "filenames_reflectances_averaged = [\n",
    "                                   date_preprocessed + '_reflectances_averaged_vb_d1.npy', # Variety B, Treatment: Fresh\n",
    "                                   date_preprocessed + '_reflectances_averaged_vb_d8.npy', # Variety B, Treatment: Deterioration\n",
    "                                   date_preprocessed + '_reflectances_averaged_vbci_d8.npy', # Variety B, Treatment: Chilling Injury-induced\n",
    "                                   date_preprocessed + '_reflectances_averaged_vc_d1.npy',\n",
    "                                   date_preprocessed + '_reflectances_averaged_vc_d8.npy',\n",
    "                                   date_preprocessed + '_reflectances_averaged_vcci_d8.npy'\n",
    "                                  ]\n",
    "\n",
    "## PSNR of images from wavelet denoising \n",
    "filenames_psnr_wavelet = [\n",
    "                          date_preprocessed + '_psnr_tensor_wavelet_vb_d1.npy', # Variety B, Treatment: Fresh\n",
    "                          date_preprocessed + '_psnr_tensor_wavelet_vb_d8.npy', # Variety B, Treatment: Deterioration\n",
    "                          date_preprocessed + '_psnr_tensor_wavelet_vbci_d8.npy', # Variety B, Treatment: Chilling Injury-induced\n",
    "                          date_preprocessed + '_psnr_tensor_wavelet_vc_d1.npy',\n",
    "                          date_preprocessed + '_psnr_tensor_wavelet_vc_d8.npy',\n",
    "                          date_preprocessed + '_psnr_tensor_wavelet_vcci_d8.npy'\n",
    "                         ]\n",
    "\n",
    "## PSNR of images from wavelet denoising and median filtering\n",
    "filenames_psnr_median = [\n",
    "                         date_preprocessed + '_psnr_median_vb_d1.npy', # Variety B, Treatment: Fresh\n",
    "                         date_preprocessed + '_psnr_median_vb_d8.npy', # Variety B, Treatment: Deterioration\n",
    "                         date_preprocessed + '_psnr_median_vbci_d8.npy', # Variety B, Treatment: Chilling Injury-induced\n",
    "                         date_preprocessed + '_psnr_median_vc_d1.npy',\n",
    "                         date_preprocessed + '_psnr_median_vc_d8.npy',\n",
    "                         date_preprocessed + '_psnr_median_vcci_d8.npy'\n",
    "                        ]\n",
    "\n",
    "\n",
    "## PSNR of images from wavelet denoising, median filtering, and triangle thresholding\n",
    "filenames_psnr_triangle = [\n",
    "                           date_preprocessed + '_psnr_tensor_triangle_vb_d1.npy', # Variety B, Treatment: Fresh\n",
    "                           date_preprocessed + '_psnr_tensor_triangle_vb_d8.npy', # Variety B, Treatment: Deterioration\n",
    "                           date_preprocessed + '_psnr_tensor_triangle_vbci_d8.npy', # Variety B, Treatment: Chilling Injury-induced\n",
    "                           date_preprocessed + '_psnr_tensor_triangle_vc_d1.npy',\n",
    "                           date_preprocessed + '_psnr_tensor_triangle_vc_d8.npy',\n",
    "                           date_preprocessed + '_psnr_tensor_triangle_vcci_d8.npy'\n",
    "                          ]\n",
    "\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# Miscellaneous variables\n",
    "# Data labels\n",
    "labels = {\n",
    "          # format <file_name>: <label_name>\n",
    "          'vb_d1': 'fresh-W',\n",
    "          'vb_d8': 'CS-W',\n",
    "          'vbci_d8': 'CI-W',\n",
    "          'vc_d1': 'fresh-S',\n",
    "          'vc_d8': 'CS-S',\n",
    "          'vcci_d8': 'CI-S',\n",
    "         }\n",
    "\n",
    "# Define color palette for visualization\n",
    "color_palette = [\n",
    "                 '#F16745', '#FFC65D', '#7BC8A4', \n",
    "                 '#4CC3D9', '#93648D', '#404040'\n",
    "                 ]\n",
    "\n",
    "# Assign head & tail wavelengths to get rid inconsistency reflectances from EDA\n",
    "head_tail = (0, 224) # Full spectrum\n",
    "test_size = 0.2 # Test size for splitting dataset\n",
    "\n",
    "# Save option\n",
    "save = False # Data saving option\n",
    "# save_figure = True # Image saving option\n",
    "number = 10 # Wavelength amount\n",
    "full = True # Full spectrum option\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# Preload variables\n",
    "wavelengths = np.fromfile(file=path_to_wavelengths, sep=',') # load list of actual wavelengths\n",
    "# wavelengths_trimmed = np.fromfile(file=path_to_wavelengths_trimmed, sep=',') # load list of trimmed wavelengths\n",
    "num_classes = len(set(labels)) # Classes number\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06465deb",
   "metadata": {
    "id": "06465deb"
   },
   "source": [
    "### 1.3. Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e58a7f",
   "metadata": {
    "executionInfo": {
     "elapsed": 454,
     "status": "aborted",
     "timestamp": 1659173830005,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "d5e58a7f"
   },
   "outputs": [],
   "source": [
    "# Network type indicator\n",
    "is_network = False # Neural network model type option\n",
    "is_load_model = True # Loading neural network model option\n",
    "is_exclude = False # Exclude some noisy head and tail wavelengths from wavelength selection\n",
    "model_name = 'plsr' # Model name\n",
    "\n",
    "# Image classification approach using CNN algorithm\n",
    "verbose = 1 # Verbosity\n",
    "is_slice = True\n",
    "epochs = 500 # Epoch of training network algorithm\n",
    "\n",
    "# Signal processing approach using PLSR\n",
    "max_components = 13 # ~ min(sample_number, feature_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d34bc",
   "metadata": {
    "id": "5f2d34bc"
   },
   "source": [
    "## 2. Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc0f9f",
   "metadata": {
    "id": "26bc0f9f"
   },
   "source": [
    "### 2.1. Data I/O Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2d781",
   "metadata": {
    "executionInfo": {
     "elapsed": 454,
     "status": "aborted",
     "timestamp": 1659173830005,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "91b2d781"
   },
   "outputs": [],
   "source": [
    "# Define function to loading processed data\n",
    "def load_dataset(path_to_files: str,\n",
    "                 dataname: str):\n",
    "    \n",
    "    '''\n",
    "    Function to loading processed data\n",
    "    loaded data from assigned 'path_to_file' including current date and assigned name\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import os\n",
    "    import numpy as np\n",
    "    \n",
    "    print('begin to loading ', dataname)\n",
    "    \n",
    "    data = np.load(file=os.path.join(path_to_files, dataname)) # Load dataset\n",
    "    \n",
    "    print('loading ', dataname , 'done')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eacc46",
   "metadata": {
    "executionInfo": {
     "elapsed": 454,
     "status": "aborted",
     "timestamp": 1659173830005,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "55eacc46"
   },
   "outputs": [],
   "source": [
    "# Define function to perform load datasets from given path and filenames then merge together\n",
    "def merge_datasets(path_to_files: str,\n",
    "                   filenames: str,\n",
    "                   is_y: bool):\n",
    "        \n",
    "    '''\n",
    "    Function to perform load dataset from given file path and filenames then merge togethers\n",
    "    steps:\n",
    "    1. Loop through filename then execute function to loading processed data.\n",
    "    2. Extract data name using Regular Expression.\n",
    "    3. Consider inside loop; y datasets checker; If \"is_y\" == True, reformat data: array => list.\n",
    "    4. Collect to global collectors.\n",
    "    5. Consider outside loop; y datasets negative checker; If \"is_y\" == False: reformat data, global collector: list => array\n",
    "    6. Loop through name; global collector for generating summary\n",
    "    7. Return output\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import re\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    # Assign global collectors\n",
    "    data = []\n",
    "    names = []\n",
    "    data_amount = []\n",
    "    \n",
    "    print('begin to merging dataset')\n",
    "    \n",
    "    # Loop through filename\n",
    "    for _, filename_i in enumerate(filenames):\n",
    "\n",
    "        # Execute function to loading processed data\n",
    "        data_temp = load_dataset(path_to_files=path_to_files,\n",
    "                                 dataname=filename_i)\n",
    "        \n",
    "        name_temp = re.search('(?<=_)\\w+', filename_i)[0] # Extract data name using Regular Expression\n",
    "        \n",
    "        # Inside loop; y datasets checker\n",
    "        if is_y == True:\n",
    "            \n",
    "            data_temp = data_temp.tolist() # Reformat data: array => list\n",
    "            \n",
    "            data.extend(data_temp) # Collect to global collector\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            data.append(data_temp) # Collect to global collector\n",
    "            \n",
    "        # Collect to global collectors\n",
    "        names.append(name_temp)\n",
    "        data_amount.append(np.shape(data_temp)[0])\n",
    "    \n",
    "    # Outside loop; y datasets negative checker\n",
    "    if is_y == False:\n",
    "        \n",
    "        data = np.vstack(data) # Reformat data, global collector: list => array\n",
    "         \n",
    "    print('merging datasets from done')\n",
    "    print('summary: ')\n",
    "    \n",
    "    # Loop through name; global collector for generating summary\n",
    "    for index, name in enumerate(names):\n",
    "    \n",
    "        print('data:', name, ', amount:', data_amount[index])\n",
    "        \n",
    "    print('\\n')\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571acc60",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1659173830006,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "571acc60"
   },
   "outputs": [],
   "source": [
    "# Define function to saving prepared dataset to directory\n",
    "def save_dataset(data,\n",
    "                 dataname: str,\n",
    "                 path_to_save: str):\n",
    "    \n",
    "    '''\n",
    "    Function to saving prepared dataset to directory\n",
    "    Save dataset to assigned 'path_to_save' with naming by current date and assigned name\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    \n",
    "    print('begin to saving data to path: ', path_to_save)\n",
    "    print('begin to saving ', dataname)\n",
    "    \n",
    "    # Save dataset with date timestamp\n",
    "    np.save(file=(path_to_save + str(date.today()) + '_' + dataname),\n",
    "            arr=data) \n",
    "    \n",
    "    print('saving ', dataname , 'done')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8b0e0",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1659173830006,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "71a8b0e0"
   },
   "outputs": [],
   "source": [
    "# Define function to convert list to DataFrame then save to directory\n",
    "def save_list_to_csv(data,\n",
    "             dataname: str,\n",
    "             path_to_save: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to convert list to DataFrame then save to directory\n",
    "    steps:\n",
    "    1. Convert list to DataFrame\n",
    "    2. Save DataFrame to csv file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    import pandas as pd\n",
    "    \n",
    "    data = pd.DataFrame(data) # Convert list to DataFrame\n",
    "    data.to_csv(path_to_save + dataname + '.csv') # Save DataFrame to csv file\n",
    "    \n",
    "    print(dataname + ' is saved to directory')\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2261d1a1",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1659173830006,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "2261d1a1"
   },
   "outputs": [],
   "source": [
    "# Define function to save model to file\n",
    "def save_model(model,\n",
    "               is_network: bool,\n",
    "               path_to_save: str,\n",
    "               filename: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to save model to file\n",
    "    Consider network-type model checker; \n",
    "    - if \"is_network\" == True: save both model and weights, \n",
    "    - otherwise: save model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import json\n",
    "    import joblib # I/O library for scikit-learn\n",
    "    \n",
    "    print('begin to save model:', filename)\n",
    "    \n",
    "    # Network-type model checker\n",
    "    if is_network == True:\n",
    "    \n",
    "        # Serialize model to JSON format\n",
    "        model_json = model.to_json()\n",
    "\n",
    "        # Open empty file to write\n",
    "        with open(\"{}.json\".format(path_to_save + filename), \"w\") as json_file:\n",
    "\n",
    "            json_file.write(model_json) # Write model to file\n",
    "\n",
    "        # Serialize weights to HDF5\n",
    "        model.save_weights(\"{}_weight.h5\".format(path_to_save + filename))\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        joblib.dump(model, path_to_save + filename + '.joblib') # save model to file \n",
    "\n",
    "    print('save model:', filename, 'done')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b253c38",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1659173830006,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "1b253c38"
   },
   "outputs": [],
   "source": [
    "# Define function to load model from file\n",
    "def load_model(is_network: bool,\n",
    "               path_to_file: str, \n",
    "               filename: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to load model from file\n",
    "    Consider network-type model checker; \n",
    "    - if \"is_network\" == True: load both model and weights, \n",
    "    - otherwise: load model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import joblib # I/O library for scikit-learn\n",
    "    from tensorflow.keras.models import model_from_json # Loading model in JSON format\n",
    "    \n",
    "    print('begin to load model:', filename)\n",
    "    \n",
    "    # Network-type model checker\n",
    "    if is_network == True:\n",
    "    \n",
    "        # Load json and create model\n",
    "        json_file = open('{}.json'.format(path_to_file + filename), 'r') # Open file\n",
    "        loaded_model_json = json_file.read() # Read file\n",
    "        json_file.close() # Close file\n",
    "        loaded_model = model_from_json(loaded_model_json) # Assign the loaded model\n",
    "\n",
    "        # Load weights into new model\n",
    "        loaded_model.load_weights(\"{}_weight.h5\".format(path_to_file + filename))\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        # Load model\n",
    "        loaded_model = joblib.load(path_to_file + filename + '_model.joblib') # Load model\n",
    "    \n",
    "    print('load model:', filename, 'done')\n",
    "    \n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed69f2",
   "metadata": {
    "id": "94ed69f2"
   },
   "source": [
    "### 2.2. Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a894f",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830009,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "605a894f"
   },
   "outputs": [],
   "source": [
    "# Define function to extract sample indices from specified label name\n",
    "def extract_indices(y: list,\n",
    "                    label: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to extract sample indices from specified label name\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract sample indices from specified label name\n",
    "    samples = [sample for sample, y_label in enumerate(y) if y_label == label]\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d5099",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830009,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "2b0d5099"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate averaged reflectance over spatial domain (width & length axises)\n",
    "def calculate_average(data,\n",
    "                      axis):\n",
    "    \n",
    "    '''\n",
    "    Function to calculate averaged reflectance over spatial domain (width & length axises) then return output as signle averaged value\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    \n",
    "    # Calculate average along spectral-axis of sample image data\n",
    "    data_averaged = np.mean(data, axis=axis)\n",
    "    \n",
    "    return data_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9d76e",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830010,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "53f9d76e"
   },
   "outputs": [],
   "source": [
    "# Define utility function to perform looping though average value calculation from multiple label data by executing function to calculate averaged reflectance over spatial domain (width & length axises)\n",
    "def calculate_average_all_data(data,\n",
    "                               y: list,\n",
    "                               labels: list):\n",
    "\n",
    "    '''\n",
    "    Utility function to perform looping though average value calculation from multiple label data by executing function to calculate averaged reflectance over spatial domain (width & length axises)\n",
    "    steps:\n",
    "    1. Loop through assigned label, extract sample indices of considering label.\n",
    "    3. Execute function to calculate averaged reflectance over spatial domain (width & length axises) then return output as signle averaged value\n",
    "    3. Collect to collector\n",
    "    4. Reformat; list => array\n",
    "    5. Return output as array\n",
    "    '''\n",
    "\n",
    "    # Assign collector\n",
    "    data_averaged_merged = []\n",
    "\n",
    "    print('begin to calculate averaged data')\n",
    "    \n",
    "    # Loop through assigned label\n",
    "    for label in labels:\n",
    "\n",
    "        # Execute function to extract sample indices from specified label name\n",
    "        samples = extract_indices(y,\n",
    "                                  label=label)\n",
    "\n",
    "        # Execute function to calculate averaged reflectance over spatial domain (width & length axises) then return output as signle averaged value\n",
    "        data_averaged = calculate_average(data=data[samples,...],\n",
    "                                          axis=(1,2))\n",
    "        # Collect to collector\n",
    "        data_averaged_merged.append(data_averaged)\n",
    "        \n",
    "    # Reformat; list => array\n",
    "    data_averaged_merged = np.vstack(data_averaged_merged)\n",
    "    \n",
    "    print('calculate averaged data done')\n",
    "        \n",
    "    return data_averaged_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4a9d6",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830010,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "dbd4a9d6"
   },
   "outputs": [],
   "source": [
    "# Define function to print iterations progress (imported from open-source)\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    \n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    \n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    \n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:    \n",
    "        print()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d1aa2",
   "metadata": {
    "id": "a06d1aa2"
   },
   "source": [
    "### 2.3. Analysis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9e6ab",
   "metadata": {
    "id": "a5d9e6ab"
   },
   "source": [
    "#### 2.3.1. CNN-related Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec3c569",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830010,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "aec3c569"
   },
   "outputs": [],
   "source": [
    "# Define function to define callback for model training\n",
    "def construct_callback(epochs,\n",
    "                       metric,\n",
    "                       verbose):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to define callback for model training\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    \n",
    "    # Define parameter\n",
    "    patience = epochs // 10\n",
    "    mode = 'min'\n",
    "\n",
    "    # Define callbacks\n",
    "    callback = EarlyStopping(\n",
    "                              monitor=metric,\n",
    "                              min_delta=0,\n",
    "                              patience=patience,\n",
    "                              verbose=verbose,\n",
    "                              mode=mode,\n",
    "                              baseline=None,\n",
    "                              restore_best_weights=False\n",
    "                              )\n",
    "    \n",
    "    return callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73939cac",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830010,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "73939cac"
   },
   "outputs": [],
   "source": [
    "# Define function to construction CNN model architecture\n",
    "def construct_cnn_model(X_train,\n",
    "                        num_classes: int,\n",
    "                        model_name: str,\n",
    "                        epochs: int,\n",
    "                        verbose: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to construction CNN model architecture\n",
    "    steps:\n",
    "    1. Construct architectures as blocks of layers\n",
    "    2. Construct model from defined layers\n",
    "    3. Return output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    from tensorflow.keras import layers # Layer API for neural network architechture\n",
    "    from tensorflow.keras import Model # Group layers into a model object\n",
    "    \n",
    "    # Define hyperparameter\n",
    "    activation = 'relu' # Convolution and Dense activation function type\n",
    "    padding = 'Same' # Convolution padding kernel\n",
    "    pool_size = (2, 2) # Max pooling and Average Pooling size\n",
    "    rate = 0.5 # Dropout rate\n",
    "    units = 200 # Dense units (Fully connected layer)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Construct architectures as blocks of layers\n",
    "    # Block 0\n",
    "    ## Input layer with shape with converting array => tensor\n",
    "    inputs = layers.Input(X_train.shape[1:],\n",
    "                          name='Input')\n",
    "        \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 1\n",
    "    ## Convolution layer\n",
    "    model_structure = layers.Conv2D(\n",
    "                                    filters=5, \n",
    "                                    kernel_size=(5, 5), \n",
    "                                    strides=(1, 1),\n",
    "                                    padding=padding, \n",
    "                                    activation=activation,\n",
    "                                    name='Convolution2D_1'\n",
    "                                    )(inputs)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 2\n",
    "    ## Convolution layer\n",
    "    model_structure = layers.Conv2D(\n",
    "                                    filters=96, \n",
    "                                    kernel_size=(7, 7), \n",
    "                                    strides=(2, 2),\n",
    "                                    padding=padding, \n",
    "                                    activation=activation,\n",
    "                                    name='Convolution2D_2'\n",
    "                                    )(model_structure)\n",
    "    \n",
    "    ## Max pooling layer\n",
    "    model_structure = layers.MaxPool2D(\n",
    "                                       pool_size=pool_size,\n",
    "                                       name='Max_Pooling_2'\n",
    "                                       )(model_structure)\n",
    "\n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_2'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 3\n",
    "    ## Convolution layer\n",
    "    model_structure = layers.Conv2D(\n",
    "                                    filters=64, \n",
    "                                    kernel_size=(5, 5), \n",
    "                                    strides=(1, 1),\n",
    "                                    padding=padding, \n",
    "                                    activation=activation,\n",
    "                                    name='Convolution2D_3'\n",
    "                                    )(model_structure)\n",
    "\n",
    "    ## Max pooling layer\n",
    "    model_structure = layers.MaxPool2D(\n",
    "                                       pool_size=pool_size,\n",
    "                                       name='Max_Pooling_3'\n",
    "                                       )(model_structure)\n",
    "\n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_3'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 4\n",
    "    ## Convolution layer\n",
    "    model_structure = layers.Conv2D(\n",
    "                                    filters=64, \n",
    "                                    kernel_size=(5, 5), \n",
    "                                    strides=(1, 1),\n",
    "                                    padding=padding, \n",
    "                                    activation=activation,\n",
    "                                    name='Convolution2D_4'\n",
    "                                    )(model_structure)\n",
    "\n",
    "    ## Max pooling layer\n",
    "    model_structure = layers.MaxPool2D(\n",
    "                                       pool_size=pool_size,\n",
    "                                       name='Max_Pooling_4'\n",
    "                                       )(model_structure)\n",
    "\n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_4'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 5\n",
    "    ## Convolution layer    \n",
    "    model_structure = layers.Conv2D(\n",
    "                                    filters=128, \n",
    "                                    kernel_size=(3, 3), \n",
    "                                    strides=(1, 1),\n",
    "                                    padding=padding, \n",
    "                                    activation=activation,\n",
    "                                    name='Convolution2D_5'\n",
    "                                    )(model_structure)\n",
    "\n",
    "    ## Average pooling layer\n",
    "    model_structure = layers.AveragePooling2D(\n",
    "                                              pool_size=pool_size,\n",
    "                                              name='Average_Pooling'\n",
    "                                              )(model_structure)\n",
    "    \n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_5'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 6\n",
    "    ## Flatten layer\n",
    "    model_structure = layers.Flatten(name='Flatten')(model_structure)\n",
    "    \n",
    "    ## Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=units, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_6'\n",
    "                                   )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 7\n",
    "    ## Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=units, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_7'\n",
    "                                   )(model_structure)\n",
    "    \n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_7'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 8\n",
    "    ## Output layer\n",
    "    outputs = layers.Dense(\n",
    "                           units=num_classes, \n",
    "                           activation=\"softmax\",\n",
    "                           name='Output'\n",
    "                           )(model_structure)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Construct model from defined layers\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "       \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Compile the constructed model\n",
    "    # Define argument\n",
    "    metric_fit = 'accuracy'\n",
    "    optimizer = 'adam'\n",
    "    loss = 'categorical_crossentropy'\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[metric_fit])\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Define callback\n",
    "    # Define argument\n",
    "    metric_callback = 'val_loss'\n",
    "\n",
    "    # Execute function to define callback for model training\n",
    "    callback = construct_callback(epochs=epochs,\n",
    "                                  metric=metric_callback,\n",
    "                                  verbose=verbose)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return model, callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166eec94",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830010,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "166eec94"
   },
   "outputs": [],
   "source": [
    "# Define function perform feature extraction as wavelength selection by image classification using CNN model\n",
    "def extract_feature_image(X,\n",
    "                          y_categorized: list,\n",
    "                          num_classes: int,\n",
    "                          test_size: float,\n",
    "                          is_slice: bool,\n",
    "                          model_name: str,\n",
    "                          epochs: int,\n",
    "                          verbose: int,\n",
    "                          wavelengths: list):\n",
    "\n",
    "    \"\"\"\n",
    "    Function perform feature extraction as wavelength selection by image classification using CNN model\n",
    "    steps:\n",
    "    1. Loop through wavelength index\n",
    "    2. Slice then split dataset\n",
    "    3. Construction CNN model architecture\n",
    "    4. Train model\n",
    "    5. Evaluate the trained model\n",
    "    6. Collect to collector\n",
    "    7. Return output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    import time\n",
    "    \n",
    "    # Define parameters\n",
    "    batch_size = X.shape[0] // 10 # Hyperparameter of sample amount to train per step\n",
    "    metric_fit = 'accuracy'\n",
    "    metric_callback = 'val_loss'\n",
    "    length_wavelengths = X.shape[-1] # Define spectral-axis length   \n",
    "    evaluation_score = np.zeros((length_wavelengths, 2)) # Define collector\n",
    "\n",
    "    start_time = time.time() # Memory starting time\n",
    "    \n",
    "    # Loop through wavelength index\n",
    "    for index in range(length_wavelengths):\n",
    "\n",
    "        print('index : wavelength =', index, ':', wavelengths[index], ' nm')\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------------------\n",
    "        # Slice then split dataset\n",
    "        # Execute function to perform data preparation by encoded y into one-hot format and split X and y follow \"test_size\"\n",
    "        X_train, X_test, y_train, y_test = prepare_dataset_image(X=X,\n",
    "                                                                 y=y_categorized,\n",
    "                                                                 num_classes=num_classes,\n",
    "                                                                 test_size=test_size,\n",
    "                                                                 is_slice=is_slice,\n",
    "                                                                 index_wavelength=index)\n",
    "    \n",
    "        # --------------------------------------------------------------------------------------------------------\n",
    "        # Train model\n",
    "        model.fit(\n",
    "                  x=X_train, \n",
    "                  y=y_train, \n",
    "                  validation_data=(X_test, y_test),\n",
    "                  batch_size=batch_size, \n",
    "                  epochs=epochs,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[callback],\n",
    "                  verbose=verbose\n",
    "                  )\n",
    "        \n",
    "        # Evaluate the trained model\n",
    "        evaluation = model.evaluate(x=X_test,\n",
    "                                    y=y_test,\n",
    "                                    verbose=verbose)\n",
    "\n",
    "        evaluation_score[index] = evaluation # Collect to collector\n",
    "\n",
    "        print('Model Evaluation:')\n",
    "        print('      Loss                    =', evaluation[0])\n",
    "        print('      Classification Accuracy =', evaluation[1], '\\n')\n",
    "        \n",
    "    end_time = time.time() # Memory ending time\n",
    "    \n",
    "    print('\\n')\n",
    "    print('total_execution time:', end_time - start_time, 'seconds \\n') # Calculate time usage    \n",
    "        \n",
    "    return model, evaluation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55933e10",
   "metadata": {
    "id": "55933e10"
   },
   "source": [
    "#### 2.3.2. PLSR-related Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e68da",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830010,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "f32e68da"
   },
   "outputs": [],
   "source": [
    "# Fefine function to perform PLS regression with specific component number\n",
    "def plsr_fit_transform(X,\n",
    "                       y: list,\n",
    "                       n_components: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to perform PLS regression with specific component number\n",
    "    steps:\n",
    "    1. Define PLS regressor with assigned component number\n",
    "    2. Fit PLS regressor with X and y\n",
    "    3. Transform X according to PLS regressor\n",
    "    4. Return output as PLS regressor and transformed X\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    from sklearn.cross_decomposition import PLSRegression\n",
    "    \n",
    "    plsr = PLSRegression(n_components=n_components) # Define PLS regressor with assigned component number\n",
    "    plsr.fit(X, y) # Fit PLS regressor with X and y\n",
    "    X_transformed = plsr.transform(X) # Transform X according to PLS regressor\n",
    "    \n",
    "    return plsr, X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ab84b",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830010,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "af2ab84b"
   },
   "outputs": [],
   "source": [
    "# Define function to perform feature extraction by component number optimization of PLS regression using MSE and cross-validation\n",
    "def extract_feature_signal(X, \n",
    "                           y: list,\n",
    "                           max_components: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to perform feature extraction by component number optimization of PLS regression using MSE and cross-validation\n",
    "    steps:\n",
    "    1. Define MSE array to be populated\n",
    "    2. Loop over the number of PLS components then regression with specified number of components, using full spectrum.\n",
    "    3. Get the list of indices that sorts the PLS coefficients in ascending order of the absolute value by ascending sorting.\n",
    "    4. Sort spectra according to ascending absolute value of PLS coefficients.\n",
    "    5. Loop through spectral-axis then discard one wavelength at a time of the sorted spectra, regress, and calculate the MSE cross-validation.\n",
    "    6. PLS regression with specified number of components with sliced wavelengths.\n",
    "    7. Caluclate cross validated label and calculate MSE.\n",
    "    8. Calculate and print the position of minimum in MSE.\n",
    "    9. Finalize by get the list of indices that sorts the PLS coefficients in ascending order of the absolute value and calculate PLS with optimal components and export values.\n",
    "    10. Select opimal parameters.\n",
    "    11. Return selected parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import time\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    \n",
    "    start_time = time.time() # memory starting time    \n",
    "    \n",
    "    # Define MSE array to be populated\n",
    "    mse = np.zeros((max_components, X.shape[-1]))\n",
    " \n",
    "    # Loop over the number of PLS components\n",
    "    for n in range(max_components):\n",
    "        \n",
    "        print('processing PLSR with component amount = {}/{}'.format(n + 1, max_components))\n",
    "        \n",
    "        # Regression with specified number of components, using full spectrum\n",
    "        # Execute function to perform PLS regression with specific component number\n",
    "        plsr1, _ = plsr_fit_transform(X=X,\n",
    "                                      y=y,\n",
    "                                      n_components=n + 1)\n",
    "        \n",
    "        \n",
    "        # Get the list of indices that sorts the PLS coefficients in ascending order of the absolute value\n",
    "        indices_sorted = np.argsort(np.abs(plsr1.coef_[:, 0])) # Ascending sorting\n",
    " \n",
    "        # Sort spectra according to ascending absolute value of PLS coefficients \n",
    "        X_calibrated = X[:, indices_sorted]\n",
    " \n",
    "        # Loop through spectral-axis\n",
    "        # Discard one wavelength at a time of the sorted spectra, regress, and calculate the MSE cross-validation\n",
    "        for m_wavelength in range(X.shape[-1] - (n + 1)):\n",
    "            \n",
    "            # PLS regression with specified number of components with sliced wavelengths\n",
    "            # Execute function to perform PLS regression with specific component number\n",
    "            plsr2, _ = plsr_fit_transform(X=X[:, m_wavelength:],\n",
    "                                          y=y,\n",
    "                                          n_components=n + 1)\n",
    "            \n",
    "            # Caluclate cross validated label\n",
    "            y_cross_validated = cross_val_predict(estimator=plsr2, \n",
    "                                                  X=X[:, m_wavelength:], \n",
    "                                                  y=y, \n",
    "                                                  cv=10)\n",
    " \n",
    "            mse[n, m_wavelength] = mean_squared_error(y, y_cross_validated) # Calculate MSE\n",
    "    \n",
    "\n",
    "            # Show progress bar\n",
    "            printProgressBar(m_wavelength + 1, \n",
    "                             X_calibrated.shape[-1] - (n + 1), \n",
    "                             prefix = 'progress:', \n",
    "                             suffix = 'complete', \n",
    "                             length = 50)    \n",
    "        \n",
    "    # Calculate and print the position of minimum in MSE\n",
    "    mse_min_x, mse_min_y = np.where(mse == np.min(mse[np.nonzero(mse)]))\n",
    " \n",
    "    print('\\n')\n",
    "    print(\"Optimized number of PLS components: \", mse_min_x[0] + 1)\n",
    "    print(\"Wavelengths to be discarded: \", mse_min_y[0])\n",
    "    print('Optimized MSEP: ', mse[mse_min_x, mse_min_y][0])\n",
    "    \n",
    "    # Finalize\n",
    "    # Calculate PLS with optimal components and export values\n",
    "    # Execute function to perform PLS regression with specific component number\n",
    "    plsr, _ = plsr_fit_transform(X=X,\n",
    "                                 y=y,\n",
    "                                 n_components=mse_min_x[0] + 1)\n",
    "        \n",
    "    # Get the list of indices that sorts the PLS coefficients in ascending order of the absolute value\n",
    "    indices_sorted = np.argsort(np.abs(plsr.coef_[:,0]))\n",
    " \n",
    "    # Sort spectra according to ascending absolute value of PLS coefficients\n",
    "    X_calibrated = X[..., indices_sorted]\n",
    "    \n",
    "    # Select opimal parameters\n",
    "    X_calibrated_optimized = X_calibrated[:,mse_min_y[0]:]\n",
    "    n_components_optimized = mse_min_x[0] + 1\n",
    "    wavelengths_discarded = mse_min_y[0]\n",
    "    \n",
    "    end_time = time.time() # Memory ending time\n",
    "\n",
    "    print('execution time:', end_time - start_time, 'seconds \\n') # Calculate time usage\n",
    " \n",
    "    return indices_sorted, X_calibrated_optimized, n_components_optimized, wavelengths_discarded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff3be1",
   "metadata": {
    "id": "1aff3be1"
   },
   "source": [
    "### 2.4. Preparation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427e1fa",
   "metadata": {
    "id": "7427e1fa"
   },
   "source": [
    "#### 2.4.1. General Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2cb541",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830011,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "de2cb541"
   },
   "outputs": [],
   "source": [
    "# Define function to encode labels from names (type: string) => label integer (type: int) and from label integers to binary class matrices\n",
    "def encode_label(y: list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to encode labels from names (type: string) => label integer (type: int) and from label integers binary class matrices\n",
    "    steps:\n",
    "    1. Encoding labels to label integers\n",
    "    2. Encoding label integers to binary class matrices\n",
    "    3. Return outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "    print('begin to label encoding')\n",
    "    \n",
    "    # Encoding labels to label integers\n",
    "    encoder = LabelEncoder() # Define label encoder\n",
    "    y_encoded = encoder.fit_transform(y) # Transform labels => encoded labels\n",
    "\n",
    "    # Encoding label integers to binary class matrices\n",
    "    y_categorized = to_categorical(y=y_encoded)\n",
    "    \n",
    "    print('label encoding done \\n')\n",
    "    \n",
    "    return y_encoded, y_categorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc3d9b",
   "metadata": {
    "id": "2cbc3d9b"
   },
   "source": [
    "#### 2.4.2. CNN-related Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57118c4",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830011,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "e57118c4"
   },
   "outputs": [],
   "source": [
    "# Define function to perform data preparation by execute function to perform data preparation by encoded y into one-hot format and split X and y follow \"test_size\"\n",
    "def prepare_dataset_image(X,\n",
    "                          y: list,\n",
    "                          num_classes: int,\n",
    "                          test_size: float,\n",
    "                          is_slice: bool,\n",
    "                          index_wavelength: int):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to perform data preparation by encoded y into one-hot format and split X and y follow \"test_size\"\n",
    "    steps:\n",
    "    1. Consider slice dataset for a single wavelength option checker, if \"is_slice\" == True: \n",
    "        - Slice dataset for spatial-axes in specific spectral-axis index\n",
    "        - Expand dimension for training Network model\n",
    "        - Set sliced dataset to X\n",
    "    1. Split the prepared X and y into train & test datasets\n",
    "    2. Return outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    print('begin to prepare dataset')\n",
    "    \n",
    "    # Slice dataset for a single wavelength option checker\n",
    "    if is_slice == True:\n",
    "        \n",
    "        # Slice dataset for spatial-axes in specific spectral-axis index\n",
    "        X_sliced = X[..., index_wavelength]\n",
    "        X_sliced = np.expand_dims(X_sliced, axis=-1) # Expand dimension for training Network model\n",
    "        X = X_sliced # Set sliced dataset to X\n",
    "        \n",
    "    # Split the prepared X and y into train & test datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y,\n",
    "                                                        test_size=test_size,\n",
    "                                                        stratify=y_encoded)\n",
    "    \n",
    "    print('prepare dataset done')\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dacd9a9",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830011,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "9dacd9a9"
   },
   "outputs": [],
   "source": [
    "# Define function to sort index evaluation score and filter dataset\n",
    "def filter_dataset(X,\n",
    "                   evaluation_score,\n",
    "                   metric: str,\n",
    "                   number: int,\n",
    "                   is_exclude: bool):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to sort index evaluation score and filter dataset\n",
    "    steps:\n",
    "    1. Consider exclude head and tail wavelengths checker, if \"is_exclude\" == True:\n",
    "       Exclude head and tail wavelengths from wavelength selection\n",
    "       \n",
    "    2. Consider filter metric option checker for loss or accuracy or mse,\n",
    "       If 'metric' == 'loss': \n",
    "           - Preparatition indices as follow loss score\n",
    "           - Obtain indices as correspond 'number' of the lowest loss score\n",
    "           - Obtain indices list sorted by evaluation metrics\n",
    "           - Loop through selected indices for print output\n",
    "       If 'metric' == 'accuracy':\n",
    "           - Preparatition indices as follow accuracy score\n",
    "           - Obtain indices as correspond 'number' of the highest accuracy score\n",
    "           - Obtain indices list sorted by evaluation metrics\n",
    "           - Loop through selected indices for print output\n",
    "        If 'metric' == 'mse':\n",
    "           - Filter option checker of PLS regression\n",
    "    3. Filter dataset using candidate indices\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    import numpy as np\n",
    "    \n",
    "    # Exclude head and tail wavelengths checker\n",
    "    if is_exclude == True:\n",
    "        \n",
    "        # Exclude head and tail wavelengths from wavelength selection\n",
    "        evaluation_score[:5, 0] = 99 # Maximize loss\n",
    "        evaluation_score[:5, 1] = 0 # Minimize accuracy\n",
    "        evaluation_score[-5:, 0] = 99 # Maximize loss\n",
    "        evaluation_score[-5:, 1] = 0 # Minimize accuracy\n",
    "            \n",
    "    # Filter metric option checker for loss\n",
    "    if metric == 'loss':\n",
    "    \n",
    "        # Preparatition indices as follow loss score\n",
    "        indices_partitioned = np.argpartition(evaluation_score[:, 0], number)[:number]\n",
    "\n",
    "        # Obtain indices as correspond 'number' of the lowest loss score\n",
    "        indices = indices_partitioned[np.argsort((-evaluation_score[:, 0])[indices_partitioned])]\n",
    "        \n",
    "        # Obtain indices list sorted by evaluation metrics\n",
    "        temp_indices = np.argpartition(evaluation_score[:, 0], (evaluation_score.shape[0] - 1))[:(evaluation_score.shape[0] - 1)]\n",
    "        indices_list_sorted = temp_indices[np.argsort((-evaluation_score[:, 0])[temp_indices])]\n",
    "        \n",
    "        # Loop through selected indices for print output\n",
    "        for index in indices:\n",
    "    \n",
    "            print('index:', index, 'score:', evaluation_score[index, 0])\n",
    "        \n",
    "    # Filter metric option checker for accuracy\n",
    "    elif metric == 'accuracy':\n",
    "    \n",
    "        # Preparatition indices as follow accuracy score\n",
    "        indices_partitioned = np.argpartition(evaluation_score[:, 1], -number)[-number:]\n",
    "\n",
    "        # Obtain indices as correspond 'number' of the highest accuracy score\n",
    "        indices = indices_partitioned[np.argsort((-evaluation_score[:, 1])[indices_partitioned])]\n",
    "        \n",
    "        # Obtain indices list sorted by evaluation metrics\n",
    "        temp_indices = np.argpartition(evaluation_score[:, 1], -1 * (evaluation_score.shape[0] - 1))[-1 * (evaluation_score.shape[0] - 1):]\n",
    "        indices_list_sorted = temp_indices[np.argsort((-evaluation_score[:, 1])[temp_indices])]\n",
    "\n",
    "        # Loop through selected indices for print output\n",
    "        for index in indices:\n",
    "    \n",
    "            print('index:', index, 'score:', evaluation_score[index, 1])\n",
    "    \n",
    "    # Filter option checker of PLS regression\n",
    "    elif metric == 'mse':\n",
    "        \n",
    "        # Slice top index corresponding to MSE\n",
    "        indices = evaluation_score[:number]\n",
    "        \n",
    "        indices_list_sorted = evaluation_score # Assign for completion\n",
    "\n",
    "        # Loop through selected indices for print output\n",
    "        for index in indices:\n",
    "    \n",
    "            print('index:', index)\n",
    "\n",
    "    # Filter dataset using candidate indices\n",
    "    X_filtered = X[..., indices]\n",
    "#     indices_sorted = sorted(indices_partitioned)\n",
    "    \n",
    "    return X_filtered, indices_list_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a1db9",
   "metadata": {
    "id": "4f1a1db9"
   },
   "source": [
    "#### 2.4.3. PLSR-related Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5380e48",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830011,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "d5380e48"
   },
   "outputs": [],
   "source": [
    "# Define function to perform data preparation with optimize parameters for visualizing plots among sepectra\n",
    "def prepare_viz_spectral(X,\n",
    "                         y_encoded: list,\n",
    "                         n_components: int,\n",
    "                         head_tail: tuple):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to perform data preparation with optimize parameters for visualizing absolute value of PLS regression coefficients\n",
    "    steps:\n",
    "    1. Slice dataset by head-tail trimming and reshape trimmed X for PLS regressor desirable shape\n",
    "    2. Execute function to perform PLS regression with specific component number\n",
    "    3. Return outputs\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare trimmed X\n",
    "    X_trimmed = X[..., head_tail[0]:head_tail[1]] # Slice dataset by head-tail trimming\n",
    "    X_trimmed_reshaped = X_trimmed.ravel().reshape(X_trimmed.shape[0],-1) # Reshape trimmed X for PLS regressor desirable shape    \n",
    "    \n",
    "    # Execute function to perform PLS regression with specific component number\n",
    "    plsr_X, _ = plsr_fit_transform(X=X_trimmed_reshaped,\n",
    "                                   y=y_encoded,\n",
    "                                   n_components=n_components)\n",
    "\n",
    "    return X_trimmed, X_trimmed_reshaped, plsr_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466beb4f",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830011,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "466beb4f"
   },
   "outputs": [],
   "source": [
    "# Define function to perform data preparation by wavelength selection then split dataset into train & test datasets\n",
    "def prepare_dataset_signal(X,\n",
    "                           y: list,\n",
    "                           indices_sorted: list,\n",
    "                           wavelengths_discarded: int,\n",
    "                           test_size: float):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to perform data preparation by wavelength selection then separate dataset into train & test datasets\n",
    "    steps:\n",
    "    1. Prepare indices; discards indices as follow optimization and unsort the discarded indices to original order\n",
    "    2. Prepare X by wavelength selection; slice X with optimize wavelength selection reshape selected X for PLS regressor desirable shape\n",
    "    3. Split the prepared X into train & test datasets\n",
    "    4. Return output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    print('begin to prepare dataset')\n",
    "    \n",
    "    # Prepare indices\n",
    "    indices_sorted_discarded = indices_sorted[:len(indices_sorted) - wavelengths_discarded] # Discards indices as follow optimization\n",
    "    indices_discarded = sorted(indices_sorted_discarded) # Unsort the discarded indices to original order\n",
    "    \n",
    "    # Prepare X by wavelength selection\n",
    "    X_prepared = X[..., indices_discarded] # Slice X with optimize wavelength selection\n",
    "    X_prepared_reshaped = X_prepared.ravel().reshape(X_prepared.shape[0], X_prepared.shape[1], X_prepared.shape[2], X_prepared.shape[3]) # Reshape selected X for PLS regressor desirable shape\n",
    "    \n",
    "    # Split the prepared X into train & test datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_prepared_reshaped, \n",
    "                                                        y,\n",
    "                                                        test_size=test_size,\n",
    "                                                        stratify=y_encoded) #!\n",
    "     \n",
    "    print('prepare dataset done')\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f340deb",
   "metadata": {
    "id": "3f340deb"
   },
   "source": [
    "### 2.5. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5dc10",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830011,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "89c5dc10"
   },
   "outputs": [],
   "source": [
    "# Define function to visualize PSNR/reflectance plot among treatments from assigned processing method\n",
    "def viz_averaged(X,\n",
    "                 y: list,\n",
    "                 labels: dict,\n",
    "                 wavelengths: list,\n",
    "                 head_tail: tuple,\n",
    "                 color_palette: list,\n",
    "                 is_plot_averaged: bool,\n",
    "                 is_plot_filtered: bool,\n",
    "                 alpha: float,\n",
    "                 mask: list,\n",
    "                 y_axis_name: str,\n",
    "                 figurename: str,\n",
    "                 save: bool,\n",
    "                 path_to_save: str,\n",
    "                 yticks: np.array):\n",
    "    \n",
    "    '''\n",
    "    Function to visualize PSNR/reflectance plot among treatments from assigned processing method\n",
    "    steps:\n",
    "    1. Define x-coordinate for plotting\n",
    "    2. Loop through labels then execute function to extract sample indices from specified label name\n",
    "    3. Loop through sample index then define y-coordinates for drawing considering sample figure\n",
    "    4. Draw individual sample figure\n",
    "    5. Consider plot averaged values option checker; if \"is_plot_averaged\" == True: add filter to figure\n",
    "    6. Consider save figure option checker; if \"save\" == True: save figure\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    from matplotlib import pyplot as plt\n",
    "    import matplotlib.collections as collections\n",
    "    \n",
    "    # Figure configuration\n",
    "    fig, ax = plt.subplots(figsize=(10,8)) # Create empty figure for drawing figures of PSNR\n",
    "    x_coordinates = np.arange(wavelengths.shape[0]) # Define x-coordinate for drawing\n",
    "    fontsize = 18\n",
    "    \n",
    "    # Loop through label\n",
    "    for index, label in enumerate(labels):\n",
    "        \n",
    "        # Execute function to extract sample indices from specified label name\n",
    "        samples = extract_indices(y,\n",
    "                                  label=label)\n",
    "        \n",
    "        # Loop through sample index\n",
    "        for sample in samples:\n",
    "            \n",
    "            # Define y-coordinates for drawing considering sample figure\n",
    "            y_coordinates = X[sample,:]\n",
    "\n",
    "            # Draw individual sample figure\n",
    "            ax.plot(x_coordinates[head_tail[0]:head_tail[1]], \n",
    "                    y_coordinates[head_tail[0]:head_tail[1]], \n",
    "                    alpha=alpha, \n",
    "                    color=color_palette[index])\n",
    "            \n",
    "        # Plot averaged values option checker\n",
    "        if is_plot_averaged == True:\n",
    "\n",
    "            # Plot averaged line\n",
    "            ax.plot(x_coordinates[head_tail[0]:head_tail[1]], \n",
    "                    np.mean(X[samples,:], axis=0)[head_tail[0]:head_tail[1]], \n",
    "                    label=labels[label], \n",
    "                    color=color_palette[index], \n",
    "                    linestyle='solid', marker='.')\n",
    "                \n",
    "        # Plot filtered wavelengths option checker\n",
    "        if is_plot_filtered == True:\n",
    "\n",
    "            # Define filter configuration\n",
    "            collection = collections.BrokenBarHCollection.span_where(\n",
    "                            x_coordinates[head_tail[0]:head_tail[1]], \n",
    "                            ymin=0, \n",
    "                            ymax=0.2, \n",
    "                            where=mask == False, \n",
    "                            facecolor='#FFFA4D', \n",
    "                            alpha=0.9)\n",
    "            \n",
    "            ax.add_collection(collection) # Add filter to figure\n",
    "            \n",
    "    # Decoration\n",
    "    plt.xticks(ticks=x_coordinates[head_tail[0]:head_tail[1]][0:-1:20], \n",
    "               labels=wavelengths[head_tail[0]:head_tail[1]][0:-1:20],\n",
    "               rotation=45,\n",
    "               fontsize=12)\n",
    "    \n",
    "    \n",
    "    plt.yticks(ticks=yticks,\n",
    "               fontsize=12)\n",
    "    \n",
    "    plt.xlabel('Wavelength (nm)', fontsize=fontsize - 2)\n",
    "    plt.ylabel(y_axis_name, fontsize=fontsize - 2)\n",
    "    plt.legend(bbox_to_anchor=(1.00, 1.00), fontsize=fontsize - 4)\n",
    "    \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurename + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurename, 'done')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153c109",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1659173830011,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "b153c109"
   },
   "outputs": [],
   "source": [
    "# Define function to ilterately visualize PSNR/reflectance plot a treatment at a time from assigned processing method by execute function to visualize PSNR/reflectance plot among treatments from assigned processing method \n",
    "def viz_averaged_iterated(X,\n",
    "                          y: list,\n",
    "                          labels: dict,\n",
    "                          wavelengths: list,\n",
    "                          head_tail: tuple,\n",
    "                          color_palette: list,\n",
    "                          is_plot_averaged: bool,\n",
    "                          is_plot_filtered: bool,\n",
    "                          alpha: float,\n",
    "                          mask: list,\n",
    "                          y_axis_name: str,\n",
    "                          figurename: str,\n",
    "                          save: bool,\n",
    "                          path_to_save: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to ilterately visualize PSNR/reflectance plot a treatment at a time from assigned processing method by execute function to visualize PSNR/reflectance plot among treatments from assigned processing method\n",
    "    steps:\n",
    "    1. Loop through label\n",
    "    2. Execute function to visualize PSNR plot among treatments from wavelet denoising\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop through label\n",
    "    for index, label in enumerate(labels):\n",
    "\n",
    "        # Execute function to visualize PSNR plot among treatments from wavelet denoising\n",
    "        viz_averaged(X=X,\n",
    "                     y=y,\n",
    "                     labels={label:labels[label]},\n",
    "                     wavelengths=wavelengths,\n",
    "                     head_tail=head_tail,\n",
    "                     color_palette=[color_palette[index]],\n",
    "                     is_plot_averaged=is_plot_averaged,\n",
    "                     is_plot_filtered=is_plot_filtered,\n",
    "                     alpha=alpha,\n",
    "                     mask=mask,\n",
    "                     y_axis_name=y_axis_name,\n",
    "                     figurename=figurename,\n",
    "                     save=save,\n",
    "                     path_to_save=path_to_save)\n",
    "                          \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781b97f",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1659173830011,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "e781b97f"
   },
   "outputs": [],
   "source": [
    "# Define function to visualize evaluation metrics from image classification\n",
    "def viz_evaluation(evaluation_score,\n",
    "                   plot: str,\n",
    "                   figurenames: list,\n",
    "                   save: bool,\n",
    "                   path_to_save: str):\n",
    "    \"\"\"\n",
    "    Function to visualize evaluation metrics from image classification\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    import seaborn as sns\n",
    "    from datetime import date\n",
    "    from matplotlib import pyplot as plt\n",
    "    \n",
    "    # Loss plot\n",
    "    ## Figure configuration\n",
    "    fontsize = 16\n",
    "    fig, ax = plt.subplots(figsize=(10,8)) # Create empty figure for drawing figure\n",
    "    color = '#205375'\n",
    "    \n",
    "    if plot == 'scatter':\n",
    "    \n",
    "        ## Draw scatter plot of loss score\n",
    "        plt.scatter(x=wavelengths, \n",
    "                    y=evaluation_score[:, 0],\n",
    "                    color=color)\n",
    "        \n",
    "        # Decoration\n",
    "        plt.title(label=figurenames[0], fontsize=fontsize)\n",
    "        plt.xlabel('Wavelength (nm)', fontsize=fontsize)\n",
    "        plt.ylabel('Loss', fontsize=fontsize)\n",
    "\n",
    "    elif plot == 'histogram':\n",
    "        \n",
    "        ## Draw histogram of loss score\n",
    "        sns.histplot(data=evaluation_score, \n",
    "                     x=evaluation_score[:, 0], \n",
    "                     kde=True,\n",
    "                     color=color)\n",
    "    \n",
    "        # Decoration\n",
    "        plt.title(label=figurenames[0], fontsize=fontsize)\n",
    "        plt.xlabel('Loss', fontsize=fontsize)\n",
    "        plt.ylabel('Count', fontsize=fontsize)\n",
    "\n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurenames[0] + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurenames[0], 'done')\n",
    "        \n",
    "    plt.show()    \n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------    \n",
    "    # Accuracy plot\n",
    "    ## Figure configuration\n",
    "    fig, ax = plt.subplots(figsize=(10,8)) # Create empty figure for drawing figure\n",
    "    color = '#F66B0E'\n",
    "    \n",
    "    if plot == 'scatter':\n",
    "    \n",
    "        ## Draw scatter plot of loss score\n",
    "        plt.scatter(x=wavelengths, \n",
    "                    y=evaluation_score[:, 1],\n",
    "                    color=color)\n",
    "        \n",
    "        # Decoration\n",
    "        plt.title(label=figurenames[1], fontsize=fontsize)\n",
    "        plt.xlabel('Wavelength (nm)', fontsize=fontsize)\n",
    "        plt.ylabel('Accuracy', fontsize=fontsize)\n",
    "\n",
    "    elif plot == 'histogram':\n",
    "        \n",
    "        ## Draw histogram of loss score\n",
    "        sns.histplot(data=evaluation_score, \n",
    "                     x=evaluation_score[:, 1], \n",
    "                     kde=True,\n",
    "                     color=color)\n",
    "    \n",
    "        # Decoration\n",
    "        plt.title(label=figurenames[1], fontsize=fontsize)\n",
    "        plt.xlabel('Accuracy', fontsize=fontsize)\n",
    "        plt.ylabel('Count', fontsize=fontsize)\n",
    "    \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurenames[1] + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurenames[1], 'done')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d74811",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830012,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "61d74811"
   },
   "outputs": [],
   "source": [
    "# Define function visualize PLS regression performance\n",
    "def viz_pls_cv(plsr,\n",
    "               X, \n",
    "               y: list, \n",
    "               figurename: str,\n",
    "               save: bool,\n",
    "               path_to_save: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function visualize PLS regression performance\n",
    "    steps:\n",
    "    1. Transpose regression coefficients for facilitate further plotting\n",
    "    2. Calculate calibration and calculate cross-validation\n",
    "    3. Calculate explained variance for calibration and cross validation\n",
    "    4. Calculate scores for calibration and cross-validation\n",
    "    5. Calculate scores for calibration and cross-validation\n",
    "    6. Calculate least square polynomial fit between labels and predicted labels from PLSR regression\n",
    "    7. Draw scatter plot of data points\n",
    "    8. Draw line plot of PLS regression fitting (using least square polynomial fit)\n",
    "    9. Draw line plot of true label\n",
    "    10. Consider option save figure option checker; if save == True: save figure\n",
    "    11. Return outputs\n",
    "    \"\"\"\n",
    " \n",
    "    # Import libraries\n",
    "    from datetime import date\n",
    "    from matplotlib import pyplot as plt\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "    \n",
    "    coeff = plsr.x_loadings_.T # Transpose regression coefficients for facilitate further plotting\n",
    "    \n",
    "    # Calculate calibration\n",
    "    y_calibrated = plsr.predict(X)\n",
    " \n",
    "    # Calculate cross-validation\n",
    "    y_cross_validated = cross_val_predict(estimator=plsr, \n",
    "                                          X=X, \n",
    "                                          y=y, \n",
    "                                          cv=10)\n",
    "    \n",
    "    # Calculate explained variance for calibration and cross validation\n",
    "    explained_variance_calibrated = explained_variance_score(y_true=y, \n",
    "                                                             y_pred=y_calibrated)\n",
    "    \n",
    "    explained_variance_cross_validated = explained_variance_score(y_true=y, \n",
    "                                                             y_pred=y_cross_validated)\n",
    "    \n",
    "    # Calculate scores for calibration and cross-validation\n",
    "    score_calibrated = r2_score(y_true=y, \n",
    "                                y_pred=y_calibrated)\n",
    "    \n",
    "    score_cross_validated = r2_score(y_true=y, \n",
    "                                     y_pred=y_cross_validated)\n",
    "    \n",
    "    # Calculate mean square error for calibration and cross validation\n",
    "    mse_calibrated = mean_squared_error(y_true=y, \n",
    "                                        y_pred=y_calibrated)\n",
    "    \n",
    "    mse_cross_validated = mean_squared_error(y_true=y, \n",
    "                                             y_pred=y_cross_validated)\n",
    "    \n",
    "    print('Explained Variance calibrated: %5.3f'  % explained_variance_calibrated)\n",
    "    print('Explained Variance cross-validated: %5.3f'  % explained_variance_cross_validated)\n",
    "    print('R2 calibrated: %5.3f'  % score_calibrated)\n",
    "    print('R2 cross-validated: %5.3f'  % score_cross_validated)\n",
    "    print('MSE calibrated: %5.3f' % mse_calibrated)\n",
    "    print('MSE cross-validated: %5.3f' % mse_cross_validated)\n",
    "    \n",
    "    # Calculate least square polynomial fit between labels and predicted labels from PLSR regression\n",
    "    coef_fitted = np.polyfit(x=y, \n",
    "                             y=y_cross_validated, \n",
    "                             deg=1)\n",
    "    \n",
    "    # Figure configuration\n",
    "    fig, ax = plt.subplots(figsize=(10,8)) # Plotting configuration\n",
    "    fontsize = '14' # Set font size\n",
    "    \n",
    "    # Draw scatter plot of data points\n",
    "    ax.scatter(x=y_cross_validated, \n",
    "               y=y, \n",
    "               color='#2d6a4f', \n",
    "               edgecolors='#14213d')\n",
    "    # Draw line plot of PLS regression fitting (using least square polynomial fit)\n",
    "    ax.plot(coef_fitted[0] * y + coef_fitted[1], \n",
    "            y,\n",
    "            color='#3a86ff', \n",
    "            label='Fit label')\n",
    "    \n",
    "    # Draw line plot of true label\n",
    "    ax.plot(y, \n",
    "            y, \n",
    "            color='#fb5607', \n",
    "            label='True label')\n",
    "    \n",
    "    # Decoration\n",
    "    plt.xlabel('Predicted label', fontsize=fontsize)\n",
    "    plt.ylabel('True label', fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize)    \n",
    "        \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurename + '_' + str(date.today()) + '.png') # save figure\n",
    "        \n",
    "        print('save figure:', figurename, 'done')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "    return coeff, y_cross_validated, mse_cross_validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b669896",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830012,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "6b669896"
   },
   "outputs": [],
   "source": [
    "# Define function to visualize confusion matrix from feature extractor\n",
    "def viz_confusion_matrix(y: list,\n",
    "                         y_cross_validated: list,\n",
    "                         figurename: str,\n",
    "                         save: bool,\n",
    "                         path_to_save: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to visualize confusion matrix of PLS regression using parameters from \"viz_pls_cv\"\n",
    "    steps:\n",
    "    1. Plot confusion matrix\n",
    "    2. Consider option save figure option checker; if save == True: save figure\n",
    "    \"\"\"\n",
    "\n",
    "    # Import libraries\n",
    "    from datetime import date\n",
    "    from matplotlib import pyplot as plt\n",
    "    from scikitplot.metrics import plot_confusion_matrix    \n",
    "    \n",
    "    # Figure configuration\n",
    "    fig, ax = plt.subplots(figsize=(8,8)) # Plotting configuration\n",
    "    fontsize = '16' # Font size\n",
    "    figsize = (8, 8) # Figure size\n",
    "    cmap = plt.cm.PuBuGn # Set color map of confusion matrix\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_true=y, \n",
    "                          y_pred=np.round(y_cross_validated), \n",
    "                          normalize=True, \n",
    "                          title=figurename, \n",
    "                          ax=ax, \n",
    "                          cmap=cmap)\n",
    "\n",
    "    # Decoration\n",
    "    num_classes = len(list(set(y)))\n",
    "    plt.axis([-0.5, num_classes - 0.5, -0.5, num_classes - 0.5])\n",
    "    plt.xlabel('Predicted label', fontsize=fontsize)\n",
    "    plt.ylabel('True label', fontsize=fontsize)\n",
    "    \n",
    "    \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurename + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurename, 'done')        \n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08876824",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830012,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "08876824"
   },
   "outputs": [],
   "source": [
    "# Define function to comparative visualize among spectral-axis\n",
    "def viz_spectral(data,\n",
    "                 indices_list: list,\n",
    "                 wavelengths: list,\n",
    "                 save: bool,\n",
    "                 figurename: str, \n",
    "                 path_to_save: str):\n",
    "    \n",
    "    '''\n",
    "    Function to comparative visualize among spectral-axis\n",
    "    steps:\n",
    "    1. Loop through assigned wavelengt for drawing 9 images, then draw image\n",
    "    2. Consider save figure option checker; if save == True: figure\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    from matplotlib import pyplot as plt # figure drawing\n",
    "    from scipy import ndimage as ndimage # image rotation\n",
    "    \n",
    "    # Figure configuration\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(10, 8), sharex=True, sharey=True)\n",
    "    fontsize = '16' # Define fontsize\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    # Loop through assigned wavelengt for drawing 9 images\n",
    "    for index, wavelength in enumerate(indices_list):\n",
    "        \n",
    "        # draw image\n",
    "        axs[index].imshow(ndimage.rotate(input=data[...,wavelength], angle=180), aspect='auto') # draw image\n",
    "        axs[index].set_title('\\u03BB = ' + str(wavelengths[wavelength]) + ' nm', fontsize=fontsize) # define image title\n",
    "        axs[index].axis(\"off\") # disable axes\n",
    "    \n",
    "    # Decoration\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurename + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurename, 'done')        \n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fda7e8",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830012,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "14fda7e8"
   },
   "outputs": [],
   "source": [
    "# Define function to visualize biplot from PLS regression results\n",
    "def viz_biplot(data,\n",
    "               X,\n",
    "               y,\n",
    "               coeff,\n",
    "               labels: dict,\n",
    "               y_encoded: list,\n",
    "               wavelengths: list,\n",
    "               color_palette: list,\n",
    "               figurename: str,\n",
    "               save: bool,\n",
    "               loadings_label: bool):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to visualize biplot from PLS regression results\n",
    "    steps:\n",
    "    1. Loop through dataset in Dataframe\n",
    "    2. Draw scatter plot of transformed value of considering dataset\n",
    "    3. Draw loading plot as correspond index\n",
    "    4. Check option to save output as argument; \"save\" == True, to save output to destination path\n",
    "    5. Check option to show loading labels; \"loadings_label\" == True, set label of loading plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from matplotlib import pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Define variables\n",
    "    X_appended_y = np.hstack((X,y_encoded[:,None])) # hstack both the array together.\n",
    "    X_appended_y_sorted = X_appended_y[X_appended_y[:, -1].argsort()] # sort the array by the last column\n",
    "    X_grouped = np.split(X_appended_y_sorted[:,:-1], np.unique(X_appended_y_sorted[:, -1], return_index=True)[1][1:]) # split the array based on unique value index\n",
    "\n",
    "    # Extract label_names from labels\n",
    "    labels = list(labels.values()) #!\n",
    "    \n",
    "    # Figure configuration\n",
    "    sns.set(font_scale=1) # option to set font scale\n",
    "    fontsize = 16 # set fontsize\n",
    "    scale_axes = 0.5 # scale value of axes\n",
    "    fig, ax = plt.subplots(figsize=(12,12)) # define figure configuration\n",
    "    \n",
    "    # Loop through X index\n",
    "    for index_X, X_separated in enumerate(X_grouped):\n",
    "\n",
    "        x_axis = X_separated[:, 0] # Define x-axis\n",
    "        y_axis = X_separated[:, 1] # Define y-axis\n",
    "        scale_x_axis = scale_axes / (x_axis.max() - x_axis.min()) # Define min-max scaler of x-axis\n",
    "        scale_y_axis = scale_axes / (y_axis.max() - y_axis.min()) # Define min-max scaler of y-axis\n",
    "        \n",
    "        label = labels[index_X]\n",
    "        color = color_palette[index_X] # Define color from color palette\n",
    "\n",
    "        # Draw scatter plot\n",
    "        scatter = ax.scatter(x_axis * scale_x_axis, \n",
    "                             y_axis * scale_y_axis,\n",
    "                             color=color, label=label)\n",
    "\n",
    "\n",
    "    # Loop through PLS regression component\n",
    "    for index_coeff in range(coeff.shape[0]):\n",
    "     \n",
    "        # Draw loading plot as correspond index\n",
    "        ax.arrow(0, 0, coeff[index_coeff, 0], coeff[index_coeff, 1], color = '#999999', alpha = 0.9)\n",
    " \n",
    "        wavelength = wavelengths[index_coeff] # define label of loading plot according to regression coefficient value\n",
    "\n",
    "        # Check option to show loading labels\n",
    "        if loadings_label == True:\n",
    "\n",
    "            # Set label of loading plot\n",
    "            plt.text(x=coeff[index_coeff, 0] * 1.15, \n",
    "                     y=coeff[index_coeff, 1] * 1.15, \n",
    "                     s='\\u03BB = ' + str(wavelength) + ' nm', color = '#777777', \n",
    "                     ha = 'center', va = 'center', fontsize=fontsize)\n",
    "\n",
    "    # Decoration\n",
    "    plt.axhline(0, color='black')\n",
    "    plt.axvline(0, color='black')\n",
    "    ax.set_xlim(-0.5, 0.5)\n",
    "    ax.set_ylim(-0.5, 0.5)\n",
    "    ax.set_xlabel('Component 1', fontsize=fontsize) # Set x-axis label\n",
    "    ax.set_ylabel('Component 2', fontsize=fontsize) # Set y-axis label\n",
    "    ax.legend(fontsize=fontsize - 4)\n",
    "\n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "        \n",
    "        file_to_save = path_to_save + figurename + '.png' # Define destination path to save file\n",
    "        fig.savefig(file_to_save) # Dave figure to destination path\n",
    "\n",
    "        print('save figure:', figurename, 'done')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942cd0b",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1659173830012,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "2942cd0b"
   },
   "outputs": [],
   "source": [
    "# Define function to visualize label distribution of label dataset\n",
    "def viz_label_distribution(y, \n",
    "                           labels: dict,\n",
    "                           name_groups: list,\n",
    "                           color_palette: list,\n",
    "                           figurename:str,\n",
    "                           path_to_save: str,\n",
    "                           save: bool):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to visualize label distribution of label dataset\n",
    "    steps:\n",
    "    1. Separate treatments by variety\n",
    "    2. Count labels\n",
    "    3. Draw variety A label distribution and draw variety B label distribution\n",
    "    4. Consider option to save figure option checker; if save == True: save figure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    from matplotlib import pyplot as plt\n",
    "    \n",
    "    # Extract label_names from labels\n",
    "    labels = list(labels.values()) #!\n",
    "    \n",
    "    # Separate treatments by variety\n",
    "    y_1 = [label for label in np.argmax(y, axis=1) if label in [0, 1, 2]] # 1st group\n",
    "    y_2 = [label for label in np.argmax(y, axis=1) if label not in [0, 1, 2]] # 2nd group\n",
    "    \n",
    "    # Count labels\n",
    "    labels_1, counts_1 = np.unique(y_1, return_counts=True) # 1st group\n",
    "    labels_2, counts_2 = np.unique(y_2, return_counts=True) # 2nd group\n",
    "    \n",
    "    # Figure configuration\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    plt.ylabel('Count', fontsize = 16)\n",
    "    fontsize = 18\n",
    "\n",
    "    # Draw 1st group distribution\n",
    "    plt.bar(labels_1, counts_1, label=name_groups[0], color=color_palette[0], edgecolor='#495057')\n",
    "\n",
    "    # Draw 2nd group distribution\n",
    "    plt.bar(labels_2, counts_2, label=name_groups[1], color=color_palette[1], edgecolor='#495057')\n",
    "\n",
    "    # Decoration\n",
    "    plt.xticks(ticks=np.arange(0,6,1), \n",
    "               labels=labels,\n",
    "               rotation = 90,\n",
    "               fontsize=fontsize - 4)\n",
    "    plt.ylabel('Count', fontsize = 16)\n",
    "    plt.xlabel('Label', fontsize = 16)\n",
    "    \n",
    "    plt.legend(fontsize=fontsize - 4)\n",
    "\n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "\n",
    "        plt.savefig(path_to_save + figurename + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurename, 'done')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135b1e8",
   "metadata": {
    "id": "9135b1e8"
   },
   "source": [
    "# 3. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5f67f",
   "metadata": {
    "id": "0ea5f67f"
   },
   "source": [
    "### 3.1. Data Acquisition\n",
    "\n",
    "Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536137c4",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1659173830012,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "536137c4"
   },
   "outputs": [],
   "source": [
    "# Execute function to perform load datasets from given path and filenames then merge together\n",
    "# Dataset\n",
    "## Variables, a.k.a. X\n",
    "X = merge_datasets(path_to_files=path_to_files,\n",
    "                   filenames=filenames_X,\n",
    "                   is_y=False)\n",
    "\n",
    "## Labels, a.k.a. y\n",
    "y = merge_datasets(path_to_files=path_to_files,\n",
    "                   filenames=filenames_y,\n",
    "                   is_y=True)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# Reflectances\n",
    "## Calibrated averaged reflectances\n",
    "reflectances_averaged = merge_datasets(path_to_files=path_to_files,\n",
    "                                       filenames=filenames_reflectances_averaged,\n",
    "                                       is_y=False)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# PSNR\n",
    "## PSNR of images from wavelet denoising \n",
    "psnr_wavelet = merge_datasets(path_to_files=path_to_files,\n",
    "                              filenames=filenames_psnr_wavelet,\n",
    "                              is_y=False)\n",
    "\n",
    "## PSNR of images from wavelet denoising and median filtering\n",
    "psnr_median = merge_datasets(path_to_files=path_to_files,\n",
    "                             filenames=filenames_psnr_median,\n",
    "                             is_y=False)\n",
    "\n",
    "## PSNR of images from wavelet denoising, median filtering, and triangle thresholding\n",
    "psnr_triangle = merge_datasets(path_to_files=path_to_files,\n",
    "                               filenames=filenames_psnr_triangle,\n",
    "                               is_y=False)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3514ab38",
   "metadata": {
    "id": "3514ab38"
   },
   "source": [
    "Explore the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bac180",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830013,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "e7bac180"
   },
   "outputs": [],
   "source": [
    "print('X feature dataset has dimesionality of', X.shape)\n",
    "\n",
    "print('y label dataset has dimesionality of', np.shape(y))\n",
    "\n",
    "print('averaged reflectances dataset has dimesionality of', reflectances_averaged.shape)\n",
    "\n",
    "print('PSNR of features from wavelet denoising has dimesionality of', psnr_wavelet.shape)\n",
    "\n",
    "print('PSNR of features from median filtering has dimesionality of', psnr_median.shape)\n",
    "\n",
    "print('PSNR of features from triangle thresholding has dimesionality of', psnr_triangle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c872d2",
   "metadata": {
    "id": "b7c872d2"
   },
   "source": [
    "Encode label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f002ad",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830013,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "b4f002ad"
   },
   "outputs": [],
   "source": [
    "# Execute function to encode labels from names (type: string) => label integer (type: int) and from label integers to binary class matrices\n",
    "y_encoded, y_categorized = encode_label(y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e43cad",
   "metadata": {
    "id": "f0e43cad"
   },
   "source": [
    "### 3.2. EDA\n",
    "\n",
    "Explore data to consider wether trimming head-tail wavelengths using spectoscopy approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53559add",
   "metadata": {
    "id": "53559add"
   },
   "source": [
    "#### 3.2.1. Averaged Reflectances from Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82425220",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1659173830013,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "82425220"
   },
   "outputs": [],
   "source": [
    "# Define metadata\n",
    "y_axis_name = 'Average Reflectance'\n",
    "figurename = 'Average Reflectances from Calibration against spectral domain'\n",
    "\n",
    "# Execute function to visualize PSNR/reflectance plot among treatments from assigned processing method\n",
    "viz_averaged(X=reflectances_averaged,\n",
    "             y=y,\n",
    "             labels=labels,\n",
    "             wavelengths=wavelengths,\n",
    "             head_tail=(0, -1),\n",
    "             color_palette=color_palette,             \n",
    "             is_plot_averaged=True,\n",
    "             is_plot_filtered=False,\n",
    "             alpha=0.1,\n",
    "             mask=[],\n",
    "             y_axis_name=y_axis_name,\n",
    "             figurename=figurename,\n",
    "             save=save,\n",
    "             path_to_save=path_to_save,\n",
    "             yticks=np.arange(0,0.25, 0.050))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7868c52",
   "metadata": {
    "id": "b7868c52"
   },
   "source": [
    "#### 3.2.2. Averaged Reflectances from Preprocessing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfdbdd",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830014,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "49cfdbdd"
   },
   "outputs": [],
   "source": [
    "# Execute utility function to perform looping average values calculation from multiple label data \n",
    "reflectances_averaged_preprocessed = calculate_average_all_data(data=X,\n",
    "                                                                y=y,\n",
    "                                                                labels=labels)\n",
    "\n",
    "# Define metadata\n",
    "y_axis_name = 'Average Reflectance'\n",
    "figurename = 'Average Reflectances from Preprocessing Methods against spectral domain'\n",
    "\n",
    "# Execute function to visualize PSNR/reflectance plot among treatments from assigned processing method\n",
    "viz_averaged(X=reflectances_averaged_preprocessed,\n",
    "             y=y,\n",
    "             labels=labels,\n",
    "             wavelengths=wavelengths,\n",
    "             head_tail=(0, -1),\n",
    "             color_palette=color_palette,             \n",
    "             is_plot_averaged=True,\n",
    "             is_plot_filtered=False,\n",
    "             alpha=0.1,\n",
    "             mask=[],\n",
    "             y_axis_name=y_axis_name,\n",
    "             figurename=figurename,\n",
    "             save=save,\n",
    "             path_to_save=path_to_save,\n",
    "             yticks=np.arange(0,0.25, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa2394",
   "metadata": {
    "id": "5afa2394"
   },
   "source": [
    "#### 3.2.4. PSNR Plot among Treatments from Wavelet Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2dc87e",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830014,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "5d2dc87e"
   },
   "outputs": [],
   "source": [
    "# Define metadata\n",
    "y_axis_name = 'PSNR'\n",
    "figurename = 'PSNR from Wavelet Denoising against spectral domain '\n",
    "\n",
    "# Execute function to visualize PSNR/reflectance plot among treatments from assigned processing method\n",
    "viz_averaged(X=psnr_wavelet,\n",
    "             y=y,\n",
    "             labels=labels,\n",
    "             wavelengths=wavelengths,\n",
    "             head_tail=(0, -1),\n",
    "             color_palette=color_palette,             \n",
    "             is_plot_averaged=True,\n",
    "             is_plot_filtered=False,\n",
    "             alpha=0.1,\n",
    "             mask=[],\n",
    "             y_axis_name=y_axis_name,\n",
    "             figurename=figurename,\n",
    "             save=save,\n",
    "             path_to_save=path_to_save,\n",
    "             yticks=np.arange(50,129, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6174ab",
   "metadata": {
    "id": "5d6174ab"
   },
   "source": [
    "#### 3.2.4. PSNR Plot among Treatments from Wavelet Denoising and Median Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45f354",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830014,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "0a45f354"
   },
   "outputs": [],
   "source": [
    "# Define metadata\n",
    "y_axis_name = 'PSNR'\n",
    "figurename = 'PSNR from Median Filtering against spectral domain'\n",
    "\n",
    "# Execute function to visualize PSNR/reflectance plot among treatments from assigned processing method\n",
    "viz_averaged(X=psnr_median,\n",
    "             y=y,\n",
    "             labels=labels,\n",
    "             wavelengths=wavelengths,\n",
    "             head_tail=(0, -1),\n",
    "             color_palette=color_palette,             \n",
    "             is_plot_averaged=True,\n",
    "             is_plot_filtered=False,\n",
    "             alpha=0.1,\n",
    "             mask=[],\n",
    "             y_axis_name=y_axis_name,\n",
    "             figurename=figurename,\n",
    "             save=save,\n",
    "             path_to_save=path_to_save,\n",
    "             yticks=np.arange(15,55, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7264e5f",
   "metadata": {
    "id": "f7264e5f"
   },
   "source": [
    "#### 3.2.5. PSNR Plot among Treatments from Wavelet Denoising, Median Filtering and T riangleThresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83787bcb",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1659173830014,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "83787bcb"
   },
   "outputs": [],
   "source": [
    "# # Define metadata\n",
    "# y_axis_name = 'PSNR'\n",
    "# figurename = 'PSNR Plot among Treatments from \\nWavelet Denoising, Median Filtering and Triangle Thresholding'\n",
    "\n",
    "# # Execute function to visualize PSNR/reflectance plot among treatments from assigned processing method\n",
    "# viz_averaged(X=psnr_triangle,\n",
    "#              y=y,\n",
    "#              labels=labels,\n",
    "#              wavelengths=wavelengths,\n",
    "#              head_tail=(0, -1),\n",
    "#              color_palette=color_palette,             \n",
    "#              is_plot_averaged=True,\n",
    "#              is_plot_filtered=False,\n",
    "#              alpha=0.1,\n",
    "#              mask=[],\n",
    "#              y_axis_name=y_axis_name,\n",
    "#              figurename=figurename,\n",
    "#              save=save,\n",
    "#              path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9997fb",
   "metadata": {
    "id": "0d9997fb"
   },
   "source": [
    "#### 3.2.6. Treatment-wised Averaged Reflectances from Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964cf9b6",
   "metadata": {
    "id": "964cf9b6"
   },
   "source": [
    "Averaged reflectances from calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca4b40",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1659173830014,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "8dca4b40"
   },
   "outputs": [],
   "source": [
    "# # Define metadata\n",
    "# y_axis_name = 'Reflectances'\n",
    "# figurename = 'Treatment-wised Averaged Reflectances from Calibration'\n",
    "\n",
    "# # Execute function to ilterately visualize PSNR/reflectance plot a treatment at a time from assigned processing method by execute function to visualize PSNR/reflectance plot among treatments from assigned processing method \n",
    "# viz_averaged_iterated(X=reflectances_averaged,\n",
    "#                       y=y,\n",
    "#                       labels=labels,\n",
    "#                       wavelengths=wavelengths,\n",
    "#                       head_tail=head_tail,\n",
    "#                       color_palette=color_palette,             \n",
    "#                       is_plot_averaged=True,\n",
    "#                       is_plot_filtered=False,\n",
    "#                       alpha=0.1,\n",
    "#                       mask=[],\n",
    "#                       y_axis_name=y_axis_name,\n",
    "#                       figurename=figurename,\n",
    "#                       save=False,\n",
    "#                       path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f34942",
   "metadata": {
    "id": "69f34942"
   },
   "source": [
    "#### 3.2.7. Treatment-wised Averaged Reflectances from Preprocessing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448fea01",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1659173830014,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "448fea01"
   },
   "outputs": [],
   "source": [
    "# # Define metadata\n",
    "# y_axis_name = 'Reflectances'\n",
    "# figurename = 'Treatment-wised Averaged Reflectances from Preprocessing Methods'\n",
    "\n",
    "# # Execute function to ilterately visualize PSNR/reflectance plot a treatment at a time from assigned processing method by execute function to visualize PSNR/reflectance plot among treatments from assigned processing method \n",
    "# viz_averaged_iterated(X=reflectances_averaged_preprocessed,\n",
    "#                       y=y,\n",
    "#                       labels=labels,\n",
    "#                       wavelengths=wavelengths,\n",
    "#                       head_tail=head_tail,\n",
    "#                       color_palette=color_palette,             \n",
    "#                       is_plot_averaged=True,\n",
    "#                       is_plot_filtered=False,\n",
    "#                       alpha=0.1,\n",
    "#                       mask=[],\n",
    "#                       y_axis_name=y_axis_name,\n",
    "#                       figurename=figurename,\n",
    "#                       save=False,\n",
    "#                       path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d329bb",
   "metadata": {
    "id": "85d329bb"
   },
   "source": [
    "#### 3.2.8. Treatment-wised PSNR Plot among Treatments from Wavelet Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738ce9f",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1659173830014,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "a738ce9f"
   },
   "outputs": [],
   "source": [
    "# # Define metadata\n",
    "# y_axis_name = 'PSNR'\n",
    "# figurename = 'Treatment-wised PSNR Plot among Treatments from Wavelet Denoising'\n",
    "\n",
    "# # Execute function to ilterately visualize PSNR/reflectaxrnce plot a treatment at a time from assigned processing method by execute function to visualize PSNR/reflectance plot among treatments from assigned processing method \n",
    "# viz_averaged_iterated(X=psnr_wavelet,\n",
    "#                       y=y,\n",
    "#                       labels=labels,\n",
    "#                       wavelengths=wavelengths,\n",
    "#                       head_tail=head_tail,\n",
    "#                       color_palette=color_palette,             \n",
    "#                       is_plot_averaged=True,\n",
    "#                       is_plot_filtered=False,\n",
    "#                       alpha=0.1,\n",
    "#                       mask=[],\n",
    "#                       y_axis_name=y_axis_name,\n",
    "#                       figurename=figurename,\n",
    "#                       save=False,\n",
    "#                       path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6117368",
   "metadata": {
    "id": "f6117368"
   },
   "source": [
    "#### 3.2.9. Treatment-wised PSNR Plot among Treatments from Wavelet Denoising and Median Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ebdcb",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1659173830014,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "0d9ebdcb"
   },
   "outputs": [],
   "source": [
    "# # Define metadata\n",
    "# y_axis_name = 'PSNR'\n",
    "# figurename = 'Treatment-wised PSNR Plot among Treatments from \\nWavelet Denoising and Median Filtering'\n",
    "\n",
    "# # Execute function to ilterately visualize PSNR/reflectance plot a treatment at a time from assigned processing method by execute function to visualize PSNR/reflectance plot among treatments from assigned processing method \n",
    "# viz_averaged_iterated(X=psnr_median,\n",
    "#                       y=y,\n",
    "#                       labels=labels,\n",
    "#                       wavelengths=wavelengths,\n",
    "#                       head_tail=head_tail,\n",
    "#                       color_palette=color_palette,             \n",
    "#                       is_plot_averaged=True,\n",
    "#                       is_plot_filtered=False,\n",
    "#                       alpha=0.1,\n",
    "#                       mask=[],\n",
    "#                       y_axis_name=y_axis_name,\n",
    "#                       figurename=figurename,\n",
    "#                       save=False,\n",
    "#                       path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2c464",
   "metadata": {
    "id": "f8e2c464"
   },
   "source": [
    "#### 3.2.10. Treatment-wised PSNR Plot among Treatments from Wavelet Denoising, Median Filtering and Triangle Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe2e8a",
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "aborted",
     "timestamp": 1659173830421,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "efbe2e8a"
   },
   "outputs": [],
   "source": [
    "# # Define metadata\n",
    "# y_axis_name = 'PSNR'\n",
    "# figurename = 'Treatment-wised PSNR Plot among Treatments from \\nWavelet Denoising, Median Filtering and Triangle Thresholding'\n",
    "\n",
    "# # Execute function to ilterately visualize PSNR/reflectance plot a treatment at a time from assigned processing method by execute function to visualize PSNR/reflectance plot among treatments from assigned processing method \n",
    "# viz_averaged_iterated(X=psnr_triangle,\n",
    "#                       y=y,\n",
    "#                       labels=labels,\n",
    "#                       wavelengths=wavelengths,\n",
    "#                       head_tail=head_tail,\n",
    "#                       color_palette=color_palette,             \n",
    "#                       is_plot_averaged=True,\n",
    "#                       is_plot_filtered=False,\n",
    "#                       alpha=0.1,\n",
    "#                       mask=[],\n",
    "#                       y_axis_name=y_axis_name,\n",
    "#                       figurename=figurename,\n",
    "#                       save=False,\n",
    "#                       path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa178ce",
   "metadata": {
    "id": "faa178ce"
   },
   "source": [
    "### 3.3. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d2feb",
   "metadata": {
    "id": "999d2feb"
   },
   "source": [
    "#### 3.3.a. Feature Extraction using Image Classification Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab540ceb",
   "metadata": {
    "id": "ab540ceb"
   },
   "source": [
    "##### 3.3.a.1. Extract Feature using Image Classification Approach\n",
    "\n",
    "**Note**: Very high resource consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111b9f7",
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "aborted",
     "timestamp": 1659173830422,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "d111b9f7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True:\n",
    "    \n",
    "    # New model training checker\n",
    "    if is_load_model == False:\n",
    "\n",
    "        # Execute function perform feature extraction as wavelength selection by image classification using CNN model\n",
    "        model, evaluation_score = extract_feature_image(X=X,\n",
    "                                                        y_categorized=y_categorized,\n",
    "                                                        num_classes=num_classes,\n",
    "                                                        test_size=test_size,\n",
    "                                                        is_slice=is_slice,   \n",
    "                                                        model_name=model_name,\n",
    "                                                        epochs=epochs,\n",
    "                                                        verbose=verbose,\n",
    "                                                        wavelengths=wavelengths)\n",
    "        \n",
    "        # Execute function to convert list to DataFrame then save to directory\n",
    "        save_list_to_csv(data=evaluation_score,\n",
    "                         dataname='evaluation_score',\n",
    "                         path_to_save=path_to_save)\n",
    "    \n",
    "    # Loaded pre-trained model checker\n",
    "    else:\n",
    "        \n",
    "        # Execute function to load model from file\n",
    "        model = load_model(is_network=is_network,\n",
    "                           path_to_file=path_to_save,\n",
    "                           filename=model_name + '_model')\n",
    "        \n",
    "        evaluation_score_df = pd.read_csv(path_to_save + 'evaluation_score.csv', index_col='Unnamed: 0') # Load pre-trained evaluation score\n",
    "        evaluation_score = evaluation_score_df.to_numpy() # Convert DataFrame to array\n",
    "        \n",
    "    model.summary() # Summary model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7a880d",
   "metadata": {
    "id": "3c7a880d"
   },
   "source": [
    "##### 3.3.a.2. Visualize Evaluation Metrics with Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e608e",
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "aborted",
     "timestamp": 1659173830422,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "402e608e"
   },
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True:\n",
    "\n",
    "    # Define arguments\n",
    "    figurenames = [\n",
    "        'Histogram of Loss from image classification',\n",
    "        'Histogram of Accuracy from image classification'\n",
    "    ]\n",
    "\n",
    "    plot = 'histogram'\n",
    "\n",
    "    # Execute function to visualize evaluation metrics from image classification\n",
    "    viz_evaluation(evaluation_score=evaluation_score,\n",
    "                   plot=plot,\n",
    "                   figurenames=figurenames,\n",
    "                   save=save,\n",
    "                   path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc9470",
   "metadata": {
    "id": "55cc9470"
   },
   "source": [
    "##### 3.3.a.3. Visualize Evaluation Metrics with Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa67e9d",
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "aborted",
     "timestamp": 1659173830422,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "daa67e9d"
   },
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True:\n",
    "\n",
    "    # Define arguments\n",
    "    figurenames = [\n",
    "        'Scatter plot between Loss from image classification',\n",
    "        'Scatter plot between Accuracy from image classification'\n",
    "    ]\n",
    "\n",
    "    plot = 'scatter'\n",
    "\n",
    "    # Execute function to visualize evaluation metrics from image classification\n",
    "    viz_evaluation(evaluation_score=evaluation_score,\n",
    "                   plot=plot,\n",
    "                   figurenames=figurenames,\n",
    "                   save=save,\n",
    "                   path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b5d09",
   "metadata": {
    "id": "145b5d09"
   },
   "source": [
    "#### 3.3.b. Feature Extraction using Spectroscopy Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05518f1",
   "metadata": {
    "id": "e05518f1"
   },
   "source": [
    "##### 3.3.b.1. Extract Feature using Spectroscopy Approach\n",
    "\n",
    "**Note**: High resource consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69188b7",
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "aborted",
     "timestamp": 1659173830422,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "b69188b7"
   },
   "outputs": [],
   "source": [
    "# Non-neural network model checker\n",
    "if is_network == False:\n",
    "    \n",
    "    # Execute function to perform feature extraction by component number optimization of PLS regression using MSE and cross-validation\n",
    "    indices_sorted, reflectances_optimized, n_components_optimized, wavelengths_discarded = extract_feature_signal(X=reflectances_averaged_preprocessed[:, head_tail[0]:head_tail[1]], \n",
    "                                                                                                                   y=y_encoded, \n",
    "                                                                                                                   max_components=max_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf0e69",
   "metadata": {
    "id": "73bf0e69"
   },
   "source": [
    "##### 3.3.b.2. Visualize Wavelength Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d96ca",
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "aborted",
     "timestamp": 1659173830422,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "8a6d96ca"
   },
   "outputs": [],
   "source": [
    "# # Neural network model checker\n",
    "# if is_network == False:\n",
    "\n",
    "#     # Define mask as follow PLSR optimization\n",
    "#     mask = np.in1d(np.arange(reflectances_averaged_preprocessed[:,head_tail[0]:head_tail[1]].shape[-1]), \n",
    "#                    indices_sorted[wavelengths_discarded:])\n",
    "\n",
    "#     # Define metadata\n",
    "#     y_axis_name = 'Reflectances'\n",
    "#     figurename = 'wavelength selection from spectrocopy approach'\n",
    "\n",
    "#     # Execute function to visualize averaged reflectances plot among treatments from image preprocessing\n",
    "#     # highlighted wavelengths ~ discarded\n",
    "#     viz_averaged(X=reflectances_averaged_preprocessed,\n",
    "#                  y=y,\n",
    "#                  labels=labels,\n",
    "#                  wavelengths=wavelengths,\n",
    "#                  head_tail=head_tail,\n",
    "#                  is_plot_averaged=True,\n",
    "#                  is_plot_filtered=True,\n",
    "#                  alpha=0.2,\n",
    "#                  color_palette=color_palette,\n",
    "#                  mask=mask,\n",
    "#                  y_axis_name=y_axis_name,\n",
    "#                  figurename=figurename,\n",
    "#                  save=save,\n",
    "#                  path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da001b6c",
   "metadata": {
    "id": "da001b6c"
   },
   "source": [
    "##### 3.3.b.2. Visualize PLSR Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff8720",
   "metadata": {
    "executionInfo": {
     "elapsed": 423,
     "status": "aborted",
     "timestamp": 1659173830422,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "43ff8720"
   },
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == False:\n",
    "\n",
    "    # Execute function to perform PLS regression with specific component number\n",
    "    model, reflectances_optimized_transformed = plsr_fit_transform(X=reflectances_optimized,\n",
    "                                                                  y=y_encoded,\n",
    "                                                                  n_components=n_components_optimized)\n",
    "    # Define metadata\n",
    "    figurename = 'Cross-validated PLS regression'\n",
    "\n",
    "    # Execute function visualize PLS regression performance\n",
    "    coeff, y_cross_validated, mse_cross_validated = viz_pls_cv(plsr=model,\n",
    "                                                               X=reflectances_optimized, \n",
    "                                                               y=y_encoded, \n",
    "                                                               figurename=figurename,\n",
    "                                                               save=save,\n",
    "                                                               path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2696af",
   "metadata": {
    "id": "db2696af"
   },
   "source": [
    "##### 3.3.b.3. Visualize Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62b024",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1659173830422,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "8a62b024"
   },
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == False:\n",
    "    \n",
    "    # Define metadata\n",
    "    figurename = 'Confusion Matrix of PLS Regression with \\nMSE = ' + str(mse_cross_validated)\n",
    "\n",
    "    # Execute function to visualize confusion matrix of PLS regression using parameters from \"viz_pls_cv\"\n",
    "    viz_confusion_matrix(y=y_encoded,\n",
    "                         y_cross_validated=y_cross_validated,\n",
    "                         figurename=figurename,\n",
    "                         save=False,\n",
    "                         path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b14c2e",
   "metadata": {
    "id": "b9b14c2e"
   },
   "source": [
    "##### 3.3.b.4. Visualize PLSR Coefficients\n",
    "\n",
    "**Note**: High resource consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1d8e6",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1659173830422,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "7ec1d8e6"
   },
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == False:\n",
    "    \n",
    "    # Prepare data for visualizing absolute value of PLS regression coefficients among spectra\n",
    "    # Execute function to perform data preparation with optimize parameters for visualizing plots among sepectra\n",
    "    X_trimmed, X_trimmed_reshaped, plsr_X = prepare_viz_spectral(X=X,\n",
    "                                                                 y_encoded=y_encoded,\n",
    "                                                                 n_components=n_components_optimized,\n",
    "                                                                 head_tail=head_tail)\n",
    "\n",
    "    # Prepare PLS regression coefficients for visualization\n",
    "    coeff_X_reshaped = plsr_X.coef_.reshape(X_trimmed.shape[1:]) # Reshape regression coefficients of trimmed X\n",
    "    indices_list = random.sample(range(X_trimmed.shape[-1]), 9) # Random 9 wavelength indices as list\n",
    "    indices_list_sorted = sorted(indices_list) # Ascending sort list of indices\n",
    "\n",
    "    # Define metadata\n",
    "    figurename = 'Absolute value of PLS regression coefficients'\n",
    "\n",
    "    # Execute function to comparative visualize among spectra\n",
    "    viz_spectral(data=coeff_X_reshaped,\n",
    "                 indices_list=indices_list,\n",
    "                 wavelengths=wavelengths,\n",
    "                 save=save,\n",
    "                 figurename=figurename,\n",
    "                 path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f03c9c",
   "metadata": {
    "id": "f4f03c9c"
   },
   "source": [
    "### 3.4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b744b7",
   "metadata": {
    "id": "d1b744b7"
   },
   "source": [
    "#### 3.4.1. Wavelength Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498f740",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1659173830423,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "5498f740"
   },
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True:\n",
    "    \n",
    "    # Define parameters\n",
    "    evaluation_score_trimmed = evaluation_score.copy() # copy original evaluation score\n",
    "    metric = 'accuracy' # Metric for wavelength selection\n",
    "\n",
    "    # execute function to sort index evaluation score and filter dataset\n",
    "    X_filtered, indices_sorted = filter_dataset(X=X,\n",
    "                                                evaluation_score=evaluation_score,\n",
    "                                                metric=metric,\n",
    "                                                number=number,\n",
    "                                                is_exclude=is_exclude)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    metric = 'mse' # Metric for wavelength selection\n",
    "    \n",
    "    # execute function to sort index evaluation score and filter dataset\n",
    "    X_filtered, _ = filter_dataset(X=X,\n",
    "                                   evaluation_score=indices_sorted,\n",
    "                                   metric=metric,\n",
    "                                   number=number,\n",
    "                                   is_exclude=is_exclude)\n",
    "    \n",
    "# Save indices list\n",
    "# Execute function to convert list to DataFrame then save to directory\n",
    "save_list_to_csv(data=indices_sorted,\n",
    "                 dataname='indices_sorted_' + model_name,\n",
    "                 path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759d6d6",
   "metadata": {
    "id": "4759d6d6"
   },
   "source": [
    "##### 3.4.2. Visualize Wavelength selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa11d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [219,210,158,223,78,179,12,216,169,187]\n",
    "result = []\n",
    "\n",
    "for index in temp:\n",
    "    \n",
    "    result.append(wavelengths[index])\n",
    "    \n",
    "sorted(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3d1b5",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1659173830423,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "1cf3d1b5"
   },
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True:\n",
    "\n",
    "    indices_list = indices_sorted[:number] # Set selected wavelengths\n",
    "    \n",
    "#     # Define mask as follow CNN optimization\n",
    "#     mask = np.in1d(np.arange(reflectances_averaged_preprocessed[:,head_tail[0]:head_tail[1]].shape[-1]), \n",
    "#                    indices_list)\n",
    "    \n",
    "    # Define figure name\n",
    "    figurename = 'Wavelength Selection from Image Classification Approach'\n",
    "    \n",
    "    # Execute function to convert list to DataFrame then save to directory\n",
    "    save_list_to_csv(data=evaluation_score,\n",
    "                     dataname='evaluation_score',\n",
    "                     path_to_save=path_to_save)\n",
    "\n",
    "# Non-neural network model checker\n",
    "else:\n",
    "    \n",
    "#     indices_list = indices_sorted[wavelengths_discarded:] # Set selected wavelengths\n",
    "    indices_list = indices_sorted[:number] # Set selected wavelengths using fixed amount\n",
    "    \n",
    "#     # Define mask as follow PLSR optimization\n",
    "#     mask = np.in1d(np.arange(reflectances_averaged_preprocessed[:,head_tail[0]:head_tail[1]].shape[-1]), \n",
    "#                    indices_list)\n",
    "    \n",
    "    # Define figure name\n",
    "    figurename = 'Wavelength Selection from Spectrocopy Approach'\n",
    "    \n",
    "# Define mask as follow optimization\n",
    "mask = np.in1d(np.arange(reflectances_averaged_preprocessed[:,head_tail[0]:head_tail[1]].shape[-1]), \n",
    "               indices_list)\n",
    "\n",
    "# Define metadata\n",
    "y_axis_name = 'Reflectance'\n",
    "\n",
    "# Execute function to visualize averaged reflectances plot among treatments from image preprocessing\n",
    "# highlighted wavelengths ~ discarded\n",
    "viz_averaged(X=reflectances_averaged_preprocessed,\n",
    "             y=y,\n",
    "             labels=labels,\n",
    "             wavelengths=wavelengths,\n",
    "             head_tail=head_tail,\n",
    "             is_plot_averaged=True,\n",
    "             is_plot_filtered=True,\n",
    "             alpha=0.1,\n",
    "             color_palette=color_palette,\n",
    "             mask=mask,\n",
    "             y_axis_name=y_axis_name,\n",
    "             figurename=figurename,\n",
    "             save=save,\n",
    "             path_to_save=path_to_save,\n",
    "             yticks=np.arange(0,0.25, 0.050))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32398374",
   "metadata": {
    "id": "32398374"
   },
   "source": [
    "#### 3.4.3. Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabcb6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c7a0d",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1659173830423,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "2f8c7a0d"
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "is_slice = False\n",
    "index_wavelength = 0\n",
    "\n",
    "# Execute function to perform data preparation by encoded y into one-hot format and split X and y follow \"test_size\"\n",
    "X_train, X_test, y_train, y_test = prepare_dataset_image(X=X_filtered,\n",
    "                                                         y=y_categorized,\n",
    "                                                         num_classes=num_classes,\n",
    "                                                         test_size=test_size,\n",
    "                                                         is_slice=is_slice,\n",
    "                                                         index_wavelength=index_wavelength)\n",
    "\n",
    "# Full spectrum option checker\n",
    "if full == True:\n",
    "    \n",
    "    # Execute function to perform data preparation by encoded y into one-hot format and split X and y follow \"test_size\"\n",
    "    X_full_train, X_full_test, y_full_train, y_full_test = prepare_dataset_image(X=X,\n",
    "                                                                                 y=y_categorized,\n",
    "                                                                                 num_classes=num_classes,\n",
    "                                                                                 test_size=test_size,\n",
    "                                                                                 is_slice=is_slice,\n",
    "                                                                                 index_wavelength=index_wavelength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df239a",
   "metadata": {
    "id": "26df239a"
   },
   "source": [
    "#### 3.4.4. Visualize the splitted training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dad843",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1659173830423,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "52dad843"
   },
   "outputs": [],
   "source": [
    "# Define metadata\n",
    "figurename = 'Distribution of Training Dataset Labels from ' + model_name.upper()\n",
    "name_groups = ['winter', 'summer']\n",
    "\n",
    "# Execute function to visualize label distribution of label dataset\n",
    "viz_label_distribution(y=y_train, \n",
    "                       labels=labels,\n",
    "                       name_groups=name_groups,\n",
    "                       color_palette=['#3a86ff', '#ffbe0b'],\n",
    "                       path_to_save=path_to_save,\n",
    "                       figurename=figurename,\n",
    "                       save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56f20d",
   "metadata": {
    "id": "2c56f20d"
   },
   "source": [
    "#### 3.4.5. Visualize the splitted testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8991949",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1659173830423,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "f8991949"
   },
   "outputs": [],
   "source": [
    "# Define metadata\n",
    "figurename = 'Distribution of Testing Dataset Labels from ' + model_name.upper()\n",
    "name_groups = ['winter', 'summer']\n",
    "\n",
    "# Execute function to visualize label distribution of label dataset\n",
    "viz_label_distribution(y=y_test, \n",
    "                       labels=labels,\n",
    "                       name_groups=name_groups,\n",
    "                       color_palette=['#205375', '#F66B0E'],\n",
    "                       path_to_save=path_to_save,\n",
    "                       figurename=figurename,\n",
    "                       save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ced5c",
   "metadata": {
    "id": "664ced5c"
   },
   "source": [
    "#### 3.4.6. Visualize Biplot (inactivated due to it set plotting style to seaborn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae2fd3",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1659173830423,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "f0ae2fd3"
   },
   "outputs": [],
   "source": [
    "# # Neural network model checker\n",
    "# if is_network == False:\n",
    "\n",
    "#     # Define metadata\n",
    "#     figurename = 'biplot of transformed dataset using PLS regression'\n",
    "\n",
    "#     # Show loadings labels\n",
    "#     # Execute function to visualize biplot from PLS regression results\n",
    "#     viz_biplot(data=reflectances_optimized,\n",
    "#                X=reflectances_optimized_transformed,\n",
    "#                y=y,\n",
    "#                y_encoded=y_encoded,\n",
    "#                coeff=coeff,\n",
    "#                labels=labels,\n",
    "#                wavelengths=wavelengths,\n",
    "#                color_palette=color_palette,\n",
    "#                figurename=figurename,\n",
    "#                save=save,\n",
    "#                loadings_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d6a275",
   "metadata": {
    "id": "d0d6a275"
   },
   "source": [
    "## 4. Data Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32fdc0",
   "metadata": {
    "id": "db32fdc0"
   },
   "source": [
    "### 4.1. Dataset Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3d0b6",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1659173830423,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "a2e3d0b6"
   },
   "outputs": [],
   "source": [
    "# Execute function to saving processed data\n",
    "# Training dataset\n",
    "save_dataset(data=X_train,\n",
    "             dataname='X_train_' + model_name,\n",
    "             path_to_save=path_to_save)\n",
    "\n",
    "# Testing dataset\n",
    "save_dataset(data=X_test,\n",
    "             dataname='X_test_' + model_name,\n",
    "             path_to_save=path_to_save)\n",
    "\n",
    "# Training labels\n",
    "save_dataset(data=y_train,\n",
    "             dataname='y_train_' + model_name,\n",
    "             path_to_save=path_to_save)\n",
    "\n",
    "# Testing labels\n",
    "save_dataset(data=y_test,\n",
    "             dataname='y_test_' + model_name,\n",
    "             path_to_save=path_to_save)\n",
    "\n",
    "# Full spectrum option checker\n",
    "if full == True:\n",
    "    \n",
    "    # Training dataset\n",
    "    save_dataset(data=X_full_train,\n",
    "                 dataname='X_train_full',\n",
    "                 path_to_save=path_to_save)\n",
    "\n",
    "    # Testing dataset\n",
    "    save_dataset(data=X_full_test,\n",
    "                 dataname='X_test_full',\n",
    "                 path_to_save=path_to_save)\n",
    "\n",
    "    # Training labels\n",
    "    save_dataset(data=y_full_train,\n",
    "                 dataname='y_train_full',\n",
    "                 path_to_save=path_to_save)\n",
    "\n",
    "    # Testing labels\n",
    "    save_dataset(data=y_full_test,\n",
    "                 dataname='y_test_full',\n",
    "                 path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d58302",
   "metadata": {
    "id": "70d58302"
   },
   "source": [
    "### 4.2. Neural Network Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeeca76",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1659173830423,
     "user": {
      "displayName": "Navavat Pipatsart",
      "userId": "00870742361683931841"
     },
     "user_tz": -420
    },
    "id": "2aeeca76"
   },
   "outputs": [],
   "source": [
    "# Execute function to save model to file\n",
    "save_model(model=model, \n",
    "           is_network=is_network,\n",
    "           path_to_save=path_to_save,\n",
    "           filename=model_name + '_model')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "5f2d34bc",
    "94ed69f2",
    "a06d1aa2",
    "a5d9e6ab",
    "55933e10",
    "1aff3be1",
    "7427e1fa",
    "2cbc3d9b",
    "4f1a1db9",
    "3f340deb",
    "b6b136c8",
    "3bdd8bc3",
    "85d329bb",
    "f6117368",
    "f8e2c464",
    "faa178ce",
    "999d2feb",
    "145b5d09",
    "f4f03c9c",
    "d1b744b7",
    "32398374",
    "26df239a",
    "2c56f20d",
    "664ced5c",
    "db32fdc0",
    "70d58302"
   ],
   "name": "2_feature_extraction_finish.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
