{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333c1d14",
   "metadata": {},
   "source": [
    "# 5. KNN Model Training and Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cca4a7",
   "metadata": {},
   "source": [
    "**Author**: Navavat Pipatsart, pnastranagant@gmail.com\n",
    "\n",
    "**language**: python\n",
    "\n",
    "**environemt**: jupyter notebook\n",
    "\n",
    "**Objective**: Employ prepared dataset from **Part 2. Exploratory Data Analysis & Data Preparation** to train model and evaluate its performance\n",
    "\n",
    "**Last modified date**: 2022-06-23\n",
    "\n",
    "**Modified issue**: implement vc data\n",
    "\n",
    "**status**: Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65f53a",
   "metadata": {},
   "source": [
    "## 1. Environmental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76202423",
   "metadata": {},
   "source": [
    "### 1.1. Miscellaneous Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9409f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "# from tensorflow.random import set_seed\n",
    "\n",
    "# System configuration\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"0\" # disable warning messages\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ec7b9",
   "metadata": {},
   "source": [
    "### 1.2. Main Configuration\n",
    "\n",
    "**NOTE**: This project datasets is located in *on-premise external harddisk*. Hence, path will be set to the located files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaafda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# Define filenames\n",
    "# !!! priority recheck\n",
    "date_prepared = '2022-06-22' # data preparation date\n",
    "method_prepared = 'full' # data preparation method: ('full', cnn', 'plsr')\n",
    "    \n",
    "filename_X_train = date_prepared + '_X_train_' + method_prepared + '.npy' # Training variables, a.k.a. X train.\n",
    "filename_X_test = date_prepared + '_X_test_' + method_prepared + '.npy' # Testing variables, a.k.a. X test.\n",
    "filename_y_train = date_prepared + '_y_train_' + method_prepared + '.npy' # Training labels, a.k.a. y train.\n",
    "filename_y_test = date_prepared + '_y_test_' + method_prepared + '.npy' # Testing labels, a.k.a. y test.\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# Define paths\n",
    "parent_path = '/Volumes/phdbackup/backup/processed_data/' # Parent path to pre-processed files and path to save.\n",
    "\n",
    "# !!! priority recheck\n",
    "children_path_to_files = 'prepared_data_20220622/' # Children path to prepared files.\n",
    "\n",
    "# !!! priority recheck\n",
    "children_path_to_save = 'trained_data_20220816/cnn/' # Children path to save.\n",
    "\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "path_to_files = parent_path + children_path_to_files # Full path to files.\n",
    "path_to_save = parent_path + children_path_to_save # Full path to save.\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# Miscellaneous variables\n",
    "# Save option\n",
    "save = True\n",
    "\n",
    "# Data labels\n",
    "labels = [\n",
    "          'fresh-W', \n",
    "          'CS-W', \n",
    "          'CI-W',\n",
    "          'fresh-S', \n",
    "          'CS-S', \n",
    "          'CI-S'\n",
    "          ]\n",
    "\n",
    "num_classes = len(set(labels)) # Classes number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414dfc3",
   "metadata": {},
   "source": [
    "### KNN configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdbbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters configuration\n",
    "# ## Model training\n",
    "# verbose = 1 # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "\n",
    "# # Hyperparameters of the model for optimization\n",
    "# param_distributions = {\n",
    "#                        'n_neighbors': np.arange(3, 22, 2), # Number of neighbors to use by default for kneighbors queries.\n",
    "#                        'weights': ['uniform'], #! ['distance'], # Weight function used in prediction.\n",
    "#                        'algorithm': ['auto'], #! 'ball_tree', 'kd_tree', 'brute'], # Algorithm used to compute the nearest neighbors.\n",
    "#                        'leaf_size': [30], # Leaf size passed to BallTree or KDTree.\n",
    "#                        'p': [2], # Power parameter for the Minkowski metric.\n",
    "#                        'metric': ['minkowski'], # The distance metric to use for the tree.\n",
    "#                        'metric_params': [None], # Additional keyword arguments for the metric function.\n",
    "#                        'n_jobs': [-1], # The number of parallel jobs to run for neighbors search.\n",
    "#                        }\n",
    "\n",
    "# # --------------------------------------------------------------------------------------------------------\n",
    "# # Model configuration\n",
    "# ## Model I/O\n",
    "# model_name = 'knn_model' # Model name & filename\n",
    "# model_name_figure = model_name.upper().split('_')[0] # Model name for showing in figures\n",
    "# is_network = False # Network-type indicator\n",
    "# cmap = plt.cm.YlGn # Color map of confusion matrix\n",
    "\n",
    "# # --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc155295",
   "metadata": {},
   "source": [
    "### SVM configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a568c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters configuration\n",
    "# ## Model training\n",
    "# verbose = 1 # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "\n",
    "# param_distributions = {'C': [1.0], # Regularization parameter.\n",
    "#                      'break_ties': [False], # break ties according to the confidence values of decision_function\n",
    "#                      'class_weight': [None], # Set the parameter C of class i to class_weight[i]*C for SVC.\n",
    "#                      'decision_function_shape': ['ovr'], # Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function\n",
    "#                      'degree': [3], # Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.\n",
    "#                      'gamma': ['scale'], # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
    "#                      'kernel': ['rbf'], # Specifies the kernel type to be used in the algorithm.\n",
    "#                      'probability': [True], # Whether to enable probability estimates, will slow down that method as it internally uses 5-fold cross-validation.\n",
    "#                       }\n",
    "\n",
    "# # --------------------------------------------------------------------------------------------------------\n",
    "# # Model configuration\n",
    "# ## Model I/O\n",
    "# model_name = 'svm_model' # Model name & filename\n",
    "# model_name_figure = model_name.upper().split('_')[0] # Model name for showing in figures\n",
    "# is_network = False # Network-type indicator\n",
    "# cmap = plt.cm.YlOrBr # Color map of confusion matrix\n",
    "\n",
    "# # --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17306ce6",
   "metadata": {},
   "source": [
    "### RFC configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d80840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters configuration\n",
    "# ## Model training\n",
    "# verbose = 1 # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "\n",
    "# # Define hyperparameters of the model for optimizationxw\n",
    "# param_distributions = {\n",
    "#                        'n_estimators': np.arange(100, 1100, 500), # The number of trees in the forest.\n",
    "#                        'criterion': ['gini', 'entropy'], #! 'entropy'], # The function to measure the quality of a split.\n",
    "#                        'max_depth': [None], # The maximum depth of the tree.\n",
    "#                        'min_samples_split': [2, 0.1], #! , 0.1], # The minimum number of samples required to split an internal node.\n",
    "#                        'min_samples_leaf': [1, 0.1], #!, 0.1], # The minimum number of samples required to be at a leaf node.\n",
    "#                        'min_weight_fraction_leaf': [0.0], # The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node.\n",
    "#                        'max_features': ['auto'], #! 'log2'], # The number of features to consider when looking for the best split.\n",
    "#                        'max_leaf_nodes': [None], # Grow trees with \"max_leaf_nodes\" in best-first fashion.\n",
    "#                        'min_impurity_decrease': [0.0], # A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "#                        'bootstrap': [True], # Whether bootstrap samples are used when building trees.\n",
    "#                        'oob_score': [False], # Whether to use out-of-bag samples to estimate the generalization score.\n",
    "#                        'n_jobs': [-1], # The number of jobs to run in parallel.\n",
    "#                        'random_state': [None], # Controls both the randomness of the bootstrapping of the samples used when building trees.\n",
    "#                        'warm_start': [True, False], #! [True, False], # When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest.\n",
    "#                        'class_weight': ['balanced', 'balanced_subsample', None], # Weights associated with classes\n",
    "#                        'ccp_alpha': [0.0], # Complexity parameter used for Minimal Cost-Complexity Pruning.\n",
    "#                        'max_samples': [None] # If bootstrap is True, the number of samples to draw from X to train each base estimator.\n",
    "#                        }\n",
    "\n",
    "# # --------------------------------------------------------------------------------------------------------\n",
    "# # Model configuration\n",
    "# ## Model I/O\n",
    "# model_name = 'rfc_model' # Model name & filename\n",
    "# model_name_figure = model_name.upper().split('_')[0] # Model name for showing in figures\n",
    "# is_network = False # Network-type indicator\n",
    "# cmap = plt.cm.GnBu # Color map of confusion matrix\n",
    "\n",
    "# # --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751cc511",
   "metadata": {},
   "source": [
    "### MLP configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c13ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters configuration\n",
    "# # batch_size = 12 # Number of samples per gradient update.\n",
    "# epochs = 1000 # Number of epochs to train the model.\n",
    "# verbose = 1 # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "    \n",
    "# # --------------------------------------------------------------------------------------------------------\n",
    "# # Model configuration\n",
    "# ## Model I/O\n",
    "# model_name = 'mlp_model' # Model name & filename\n",
    "# model_name_figure = model_name.upper().split('_')[0] # Model name for showing in figures\n",
    "# is_network = True # Network-type indicator\n",
    "# cmap = plt.cm.Blues # Color map of confusion matrix\n",
    "\n",
    "# # --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f266124",
   "metadata": {},
   "source": [
    "### CNN configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d460969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters configuration\n",
    "# batch_size = 12 # Number of samples per gradient update.\n",
    "epochs = 1000 # Number of epochs to train the model.\n",
    "verbose = 1 # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "    \n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "# Model configuration\n",
    "## Model I/O\n",
    "model_name = 'cnn_model' # Model name & filename\n",
    "model_name_figure = model_name.upper().split('_')[0] # Model name for showing in figures\n",
    "is_network = True # Network-type indicator (True: mlp, cnn; False: knn, svm, rfc)\n",
    "cmap = plt.cm.Reds # Color map of confusion matrix\n",
    "\n",
    "# # Random Seed\n",
    "# set_seed(10)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a2888",
   "metadata": {},
   "source": [
    "## 2. Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681b46b",
   "metadata": {},
   "source": [
    "### 2.1. Data I/O Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to loading processed data\n",
    "def load_dataset(path_to_files: str,\n",
    "                 dataname: str):\n",
    "    \n",
    "    '''\n",
    "    Function to loading processed data\n",
    "    loaded data from assigned 'path_to_file' including current date and assigned name\n",
    "    '''\n",
    "    \n",
    "    # Import libraries\n",
    "    import os\n",
    "    import numpy as np\n",
    "    \n",
    "    print('begin to loading ', dataname)\n",
    "    \n",
    "    data = np.load(file=os.path.join(path_to_files, dataname)) # Load dataset\n",
    "    \n",
    "    print('loading ', dataname , 'done')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934480e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to save model to file\n",
    "def save_model(model,\n",
    "               method_prepared: str,\n",
    "               is_network: bool,\n",
    "               path_to_save: str,\n",
    "               filename: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to save model to file\n",
    "    Consider network-type model checker; \n",
    "    - if \"is_network\" == True: save both model and weights, \n",
    "    - otherwise: save model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import json\n",
    "    import joblib # I/O library for scikit-learn\n",
    "    \n",
    "    print('begin to save model:', filename)\n",
    "    \n",
    "    # Network-type model checker\n",
    "    if is_network == True:\n",
    "    \n",
    "        # Serialize model to JSON format\n",
    "        model_json = model.to_json()\n",
    "\n",
    "        # Open empty file to write\n",
    "        with open(\"{}.json\".format(path_to_save + filename + '_' + method_prepared), \"w\") as json_file:\n",
    "\n",
    "            json_file.write(model_json) # Write model to file\n",
    "\n",
    "        # Serialize weights to HDF5\n",
    "        model.save_weights(\"{}_weight.h5\".format(path_to_save + filename + '_' + method_prepared))\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        joblib.dump(model, path_to_save + filename + '_' + method_prepared + '.joblib') # save model to file \n",
    "\n",
    "    print('save model:', filename, 'done')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e81332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to load model from file\n",
    "def load_model(method_prepared: str,\n",
    "               is_network: bool,\n",
    "               path_to_file: str, \n",
    "               filename: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to load model from file\n",
    "    Consider network-type model checker; \n",
    "    - if \"is_network\" == True: load both model and weights, \n",
    "    - otherwise: load model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import joblib # I/O library for scikit-learn\n",
    "    from tensorflow.keras.models import model_from_json # Loading model in JSON format\n",
    "    \n",
    "    print('begin to load model:', filename)\n",
    "    \n",
    "    # Network-type model checker\n",
    "    if is_network == True:\n",
    "    \n",
    "        # Load json and create model\n",
    "        json_file = open('{}.json'.format(path_to_file + filename + '_' + method_prepared), 'r') # Open file\n",
    "        loaded_model_json = json_file.read() # Read file\n",
    "        json_file.close() # Close file\n",
    "        loaded_model = model_from_json(loaded_model_json) # Assign the loaded model\n",
    "\n",
    "        # Load weights into new model\n",
    "        loaded_model.load_weights(\"{}_weight.h5\".format(path_to_file + filename + '_' + method_prepared))\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        # Load model\n",
    "        loaded_model = joblib.load(path_to_file + filename + '_' + method_prepared + '.joblib') # Load model\n",
    "    \n",
    "    print('load model:', filename, 'done')\n",
    "    \n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf327ca",
   "metadata": {},
   "source": [
    "### 2.2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to transform labels into one-hot encoded form\n",
    "def transform_to_onehot(y,\n",
    "                        num_classes: int):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to transform label into one-hot encoded form\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    from tensorflow.keras import utils\n",
    "    \n",
    "    # Convert y to one-hot encoded format\n",
    "    y_onehot = utils.to_categorical(y=y,\n",
    "                                    num_classes=num_classes)\n",
    "    \n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to reverse-transform labels to integer-encoded labels\n",
    "def reverse_transform_from_onehot(y_onehot):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to reverse-transform labels to integer-encoded labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    import numpy as np\n",
    "    \n",
    "    # Reverse-transform labels to integer-encoded labels\n",
    "    y = np.argmax(y_onehot, axis=1)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246dc24a",
   "metadata": {},
   "source": [
    "### 2.3. Modeling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62184097",
   "metadata": {},
   "source": [
    "#### 2.3.1. CNN Modeling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97589ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to define callback for model training\n",
    "def construct_callbacks(epochs,\n",
    "                        metric,\n",
    "                        verbose):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to define callback for model training\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "    \n",
    "    # Define parameter\n",
    "    patience = epochs // 10\n",
    "    \n",
    "    mode = 'min'\n",
    "\n",
    "    # Define callbacks\n",
    "    early_stopper = EarlyStopping(\n",
    "                                  monitor=metric,\n",
    "                                  min_delta=0,\n",
    "                                  patience=patience,\n",
    "                                  verbose=verbose,\n",
    "                                  mode=mode,\n",
    "                                  baseline=None,\n",
    "                                  restore_best_weights=False\n",
    "                                  )\n",
    "    \n",
    "    # Define callbacks using Reduce learning rate when a metric has stopped improving\n",
    "    learning_rate_reducer = ReduceLROnPlateau(monitor=metric, \n",
    "                                              factor=0.1,\n",
    "                                              patience=patience // 2,\n",
    "                                              verbose=1,\n",
    "                                              min_lr=1e-6)\n",
    "    \n",
    "    callbacks = [early_stopper, learning_rate_reducer]\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to construction CNN model architecture\n",
    "def construct_cnn_model(X_train,\n",
    "                        num_classes: int,\n",
    "                        model_name: str,\n",
    "                        epochs: int,\n",
    "                        verbose: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to construction CNN model architecture\n",
    "    steps:\n",
    "    1. Construct architectures as blocks of layers\n",
    "    2. Construct model from defined layers\n",
    "    3. Return output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    from tensorflow.keras import layers # Layer API for neural network architechture\n",
    "    from tensorflow.keras import Model # Group layers into a model object\n",
    "    \n",
    "    # Define hyperparameter\n",
    "    activation = 'relu' # Convolution and Dense activation function type\n",
    "    padding = 'Same' # Convolution padding kernel\n",
    "    pool_size = (2, 2) # Max pooling and Average Pooling size\n",
    "    rate = 0.5 # Dropout rate\n",
    "    units = 200 # Dense units (Fully connected layer)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Construct architectures as blocks of layers\n",
    "    # Block 0\n",
    "    ## Input layer with shape with converting array => tensor\n",
    "    inputs = layers.Input(X_train.shape[1:],\n",
    "                          name='Input')\n",
    "        \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 1\n",
    "    ## Convolution layer\n",
    "    model_structure = layers.Conv2D(\n",
    "                                    filters=5, \n",
    "                                    kernel_size=(5, 5), \n",
    "                                    strides=(1, 1),\n",
    "                                    padding=padding, \n",
    "                                    activation=activation,\n",
    "                                    name='Convolution2D_1'\n",
    "                                    )(inputs)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 2\n",
    "    ## Convolution layer\n",
    "    model_structure = layers.Conv2D(\n",
    "                                    filters=96, \n",
    "                                    kernel_size=(7, 7), \n",
    "                                    strides=(2, 2),\n",
    "                                    padding=padding, \n",
    "                                    activation=activation,\n",
    "                                    name='Convolution2D_2'\n",
    "                                    )(model_structure)\n",
    "    \n",
    "    ## Max pooling layer\n",
    "    model_structure = layers.MaxPool2D(\n",
    "                                       pool_size=pool_size,\n",
    "                                       name='Max_Pooling_2'\n",
    "                                       )(model_structure)\n",
    "\n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_2'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 3\n",
    "    ## Convolution layer\n",
    "    model_structure = layers.Conv2D(\n",
    "                                    filters=64, \n",
    "                                    kernel_size=(5, 5), \n",
    "                                    strides=(1, 1),\n",
    "                                    padding=padding, \n",
    "                                    activation=activation,\n",
    "                                    name='Convolution2D_3'\n",
    "                                    )(model_structure)\n",
    "\n",
    "    ## Max pooling layer\n",
    "    model_structure = layers.MaxPool2D(\n",
    "                                       pool_size=pool_size,\n",
    "                                       name='Max_Pooling_3'\n",
    "                                       )(model_structure)\n",
    "\n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_3'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 4\n",
    "    ## Convolution layer\n",
    "    model_structure = layers.Conv2D(\n",
    "                                    filters=64, \n",
    "                                    kernel_size=(5, 5), \n",
    "                                    strides=(1, 1),\n",
    "                                    padding=padding, \n",
    "                                    activation=activation,\n",
    "                                    name='Convolution2D_4'\n",
    "                                    )(model_structure)\n",
    "\n",
    "    ## Max pooling layer\n",
    "    model_structure = layers.MaxPool2D(\n",
    "                                       pool_size=pool_size,\n",
    "                                       name='Max_Pooling_4'\n",
    "                                       )(model_structure)\n",
    "\n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_4'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 5\n",
    "    ## Convolution layer    \n",
    "    model_structure = layers.Conv2D(\n",
    "                                    filters=128, \n",
    "                                    kernel_size=(3, 3), \n",
    "                                    strides=(1, 1),\n",
    "                                    padding=padding, \n",
    "                                    activation=activation,\n",
    "                                    name='Convolution2D_5'\n",
    "                                    )(model_structure)\n",
    "\n",
    "    ## Average pooling layer\n",
    "    model_structure = layers.AveragePooling2D(\n",
    "                                              pool_size=pool_size,\n",
    "                                              name='Average_Pooling'\n",
    "                                              )(model_structure)\n",
    "    \n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_5'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 6\n",
    "    ## Flatten layer\n",
    "    model_structure = layers.Flatten(name='Flatten')(model_structure)\n",
    "    \n",
    "    ## Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=units, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_6'\n",
    "                                   )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 7\n",
    "    ## Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=units, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_7'\n",
    "                                   )(model_structure)\n",
    "    \n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_7'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 8\n",
    "    ## Output layer\n",
    "    outputs = layers.Dense(\n",
    "                           units=num_classes, \n",
    "                           activation=\"softmax\",\n",
    "                           name='Output'\n",
    "                           )(model_structure)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Construct model from defined layers\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "       \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Compile the constructed model\n",
    "    # Define argument\n",
    "    metric_fit = 'accuracy'\n",
    "    optimizer = 'adam'\n",
    "    loss = 'categorical_crossentropy'\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[metric_fit])\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Define callback\n",
    "    # Define argument\n",
    "    metric_callback = 'val_loss'\n",
    "\n",
    "    # Execute function to define callback for model training\n",
    "    callbacks = construct_callbacks(epochs=epochs,\n",
    "                                    metric=metric_callback,\n",
    "                                    verbose=verbose)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f2ce9",
   "metadata": {},
   "source": [
    "#### 2.3.2. MLP Modeling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to construction MLP model architecture\n",
    "def construct_mlp_model(X_train,\n",
    "                        num_classes: int,\n",
    "                        model_name: str,\n",
    "                        epochs: int,\n",
    "                        verbose: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to construction CNN model architecture\n",
    "    steps:\n",
    "    1. Construct architectures as blocks of layers\n",
    "    2. Construct model from defined layers\n",
    "    3. Return output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    from tensorflow.keras import layers # Layer API for neural network architechture\n",
    "    from tensorflow.keras import Model # Group layers into a model object\n",
    "    \n",
    "    # Define hyperparameter\n",
    "    activation = 'relu' # Dense activation function type\n",
    "    rate = 0.5 # Dropout rate\n",
    "    units = 200 # Dense units (Fully connected layer)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Construct architectures as blocks of layers\n",
    "    # Block 0\n",
    "    ## Input layer with shape with converting array => tensor\n",
    "    inputs = layers.Input(X_train.shape[1:],\n",
    "                          name='Input')\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 1\n",
    "    ## Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=5, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_1'\n",
    "                                   )(inputs)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 2\n",
    "    ## Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=96, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_2'\n",
    "                                   )(model_structure)\n",
    "\n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_2'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 3\n",
    "    ## Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=64, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_3'\n",
    "                                   )(model_structure)\n",
    "\n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_3'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 4\n",
    "    # Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=64, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_4'\n",
    "                                   )(model_structure)\n",
    "\n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_4'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 5\n",
    "    # Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=128, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_5'\n",
    "                                   )(model_structure)\n",
    "    \n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_5'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 6\n",
    "    ## Flatten layer\n",
    "    model_structure = layers.Flatten(name='Flatten')(model_structure)\n",
    "    \n",
    "    ## Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=units, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_6'\n",
    "                                   )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 7\n",
    "    ## Dense layer\n",
    "    model_structure = layers.Dense(\n",
    "                                   units=units, \n",
    "                                   activation=activation,\n",
    "                                   name='Dense_7'\n",
    "                                   )(model_structure)\n",
    "    \n",
    "    ## Dropout layer\n",
    "    model_structure = layers.Dropout(\n",
    "                                     rate=rate,\n",
    "                                     name='Drop_out_7'\n",
    "                                     )(model_structure)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Block 8\n",
    "    ## Output layer\n",
    "    outputs = layers.Dense(\n",
    "                           units=num_classes, \n",
    "                           activation=\"softmax\",\n",
    "                           name='Output'\n",
    "                           )(model_structure)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Construct model from defined layers\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Compile the constructed model\n",
    "    # Define argument\n",
    "    metric_fit = 'accuracy'\n",
    "    optimizer = 'adam'\n",
    "    loss = 'categorical_crossentropy'\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[metric_fit])\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Define callback\n",
    "    # Define argument\n",
    "    metric_callback = 'val_loss'\n",
    "\n",
    "    # Execute function to define callback for model training\n",
    "    callbacks = construct_callbacks(epochs=epochs,\n",
    "                                    metric=metric_callback,\n",
    "                                    verbose=verbose)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7560daab",
   "metadata": {},
   "source": [
    "#### 2.3.3. Non-network ML Modeling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ddba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to assign estimator according to the model name\n",
    "def prepare_estimator(model_name: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to assign estimator according to the model name\n",
    "    Consider model name then assign estimator\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "    \n",
    "    # Estimator checker\n",
    "    # KNN model\n",
    "    if model_name == 'knn_model':\n",
    "        \n",
    "        estimator = KNeighborsClassifier() # Assign estimator as corresponding to model name\n",
    "        \n",
    "    # SVM model\n",
    "    elif model_name == 'svm_model':\n",
    "        \n",
    "        estimator = SVC() # Assign estimator as corresponding to model name\n",
    "        \n",
    "    # RFC model\n",
    "    elif model_name == 'rfc_model':\n",
    "        \n",
    "        estimator = RandomForestClassifier() # Assign estimator as corresponding to model name\n",
    "        \n",
    "    # GBC model\n",
    "    elif model_name == 'gbc_model':\n",
    "        \n",
    "        estimator = GradientBoostingClassifier() # Assign estimator as corresponding to model name\n",
    "        \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f5b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform Randomized search on hyperparameters over specified \"param_distributions\" values for an estimator\n",
    "def optimize_parameter(X_train,\n",
    "                       y_train,\n",
    "                       estimator,\n",
    "                       n_jobs: int,\n",
    "                       param_distributions: dict,\n",
    "                       verbose: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to perform Randomized search on hyperparameters over specified \"param_distributions\" values for an estimator\n",
    "    steps:\n",
    "    1. Define score function as accuracy\n",
    "    2. Determines the cross-validation splitting strategy\n",
    "    3. Define hyperparameter optimizer\n",
    "    4. Optimize hyperparameters then fit model with best hyperparameters of the assigned estimator to dataset\n",
    "    5. Return output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import time\n",
    "    from sklearn.metrics import make_scorer, accuracy_score\n",
    "    from sklearn.model_selection import ParameterGrid, RandomizedSearchCV, StratifiedKFold\n",
    "    \n",
    "    start_time = time.time() # memory starting time    \n",
    "    \n",
    "    # Define score function as accuracy\n",
    "    scoring = make_scorer(score_func=accuracy_score)\n",
    "    \n",
    "    # Define hyperparameters of the model\n",
    "#     n_jobs = -1 # Number of jobs to run in parallel. -1 means using all processors.\n",
    "    refit = 'accuracy' #! True # Refit an estimator using the best found parameters on the whole dataset.\n",
    "\n",
    "    # Determines the cross-validation splitting strategy.\n",
    "    # This cross-validation object is a variation of KFold that returns stratified folds. \n",
    "    # The folds are made by preserving the percentage of samples for each class.\n",
    "    cv = StratifiedKFold(n_splits=5, \n",
    "                         shuffle=True)\n",
    "\n",
    "    # Define hyperparameter optimizer\n",
    "    model = RandomizedSearchCV(estimator=estimator,\n",
    "                               param_distributions=param_distributions,\n",
    "                               scoring=scoring,\n",
    "                               n_jobs=n_jobs,\n",
    "                               refit=refit,\n",
    "                               verbose=verbose,\n",
    "                               cv=cv)\n",
    "\n",
    "    # Optimize hyperparameters then fit model with best hyperparameters of the assigned estimator to dataset\n",
    "    model.fit(X=X_train, \n",
    "              y=y_train)\n",
    "\n",
    "    print('\\nbest hyperparameters:')\n",
    "    print('                    ',  model.best_params_, '\\n')\n",
    "\n",
    "    end_time = time.time() # Memory ending time\n",
    "\n",
    "    print('execution time:', end_time - start_time, 'seconds \\n') # Calculate time usage\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da596033",
   "metadata": {},
   "source": [
    "### 2.4. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to visualize model structure\n",
    "def viz_model(model,\n",
    "              method_prepared: str,\n",
    "              save: bool,\n",
    "              figurename: str,\n",
    "              path_to_save: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to visualize model structure\n",
    "    steps:\n",
    "    1. Consider save option checker; if \"save\" == True: print message\n",
    "    2. Plot model structure then save to destination path (it is fixed)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import library\n",
    "    from tensorflow.keras import utils\n",
    "    \n",
    "    # Save option checker\n",
    "    if save == True:\n",
    "        \n",
    "        print('save figure:', figurename, 'done')\n",
    "    \n",
    "    return (utils.plot_model(model=model, \n",
    "                             to_file=path_to_save + figurename + '_' + method_prepared + '.png', \n",
    "                             show_shapes=True, \n",
    "                             show_layer_names=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abe05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to visualize model performance summary\n",
    "def viz_error(history,\n",
    "              method_prepared: str,\n",
    "              save: bool,\n",
    "              path_to_save: str,\n",
    "              figurenames: list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to visualize model performance summary\n",
    "    steps:\n",
    "    1. Visualize summary of history for accuracy\n",
    "    2. Consider save figure option checker; if \"save\" == True: save figure\n",
    "    3. Visualize summary of history for loss\n",
    "    4. Consider save figure option checker; if \"save\" == True: save figure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    from matplotlib import pyplot as plt\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Accuracy\n",
    "    # Figure configuration\n",
    "    fig = plt.subplots(figsize=(10, 8))\n",
    "    fontsize = '16' # Define fontsize\n",
    "    fontsize_ticks = '12' # Define fontsize for ticks\n",
    "    \n",
    "    # Visualize summary of history for accuracy\n",
    "    # Draw figure\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    \n",
    "    # Decoration\n",
    "    plt.xlabel(xlabel='Epoch', fontsize=fontsize)\n",
    "    plt.ylabel(ylabel='Accuracy', fontsize=fontsize_ticks)\n",
    "    plt.legend(['Training', 'Testing'], fontsize=fontsize_ticks) #, loc='upper left')\n",
    "    \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurenames[0] + '_' + method_prepared + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurenames[0], 'done')        \n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Loss\n",
    "    # Visualize summary of history for loss\n",
    "    # Figure configuration\n",
    "    fig = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Draw figure\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    \n",
    "    # Decoration\n",
    "    plt.xlabel(xlabel='Epoch', fontsize=fontsize)\n",
    "    plt.ylabel(ylabel='Loss', fontsize=fontsize_ticks)\n",
    "    plt.legend(['Training', 'Testing'], fontsize=fontsize_ticks) #, loc='upper left')\n",
    "    \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurenames[1] + '_' + method_prepared + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurenames[1], 'done')        \n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to visualize confusion matrix and AUC-ROC curve of the model\n",
    "def viz_confusion_matrix_and_aucroc(y_test,\n",
    "                                    y_predicted,\n",
    "                                    y_predicted_proba,\n",
    "                                    cmap,\n",
    "                                    labels: list,\n",
    "                                    num_classes: int,\n",
    "                                    method_prepared: str,\n",
    "                                    is_network: bool,\n",
    "                                    save: bool,\n",
    "                                    path_to_save: str,\n",
    "                                    figurenames: list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to visualize confusion matrix and AUC-ROC curve of the model\n",
    "    steps:\n",
    "    1. Consider network-type model checker; if \"is_network\" == True: \n",
    "       reverse-transform labels => original format of integer-encoded labels\n",
    "    2. Visualize confusion matrix\n",
    "    3. Consider option save figure option checker; if save == True: save figure\n",
    "    4. Visualize AUC-ROC curve\n",
    "    5. Consider option save figure option checker; if save == True: save figure\n",
    "    \"\"\"\n",
    "\n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    from matplotlib import pyplot as plt\n",
    "    from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "    \n",
    "    # Network-type model checker\n",
    "    if is_network == True:\n",
    "        \n",
    "        # Reverse-transform labels => original format of integer-encoded labels\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        y_pred = np.argmax(y_predicted, axis=1)\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        y_true = y_test\n",
    "        y_pred = y_predicted\n",
    "        \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Visualize confusion matrix\n",
    "    # Figure configuration\n",
    "    fontsize = '16' # font size\n",
    "    fontsize_ticks = '12' # font size\n",
    "    \n",
    "    # Draw matrix\n",
    "    plot_confusion_matrix(y_true=y_true, \n",
    "                          y_pred=y_pred, \n",
    "                          normalize=True, \n",
    "                          figsize=(8,8),\n",
    "                          cmap=cmap)\n",
    "    # Decoration\n",
    "    plt.axis([-0.5, num_classes - 0.5, -0.5, num_classes - 0.5])\n",
    "    plt.title('', fontsize=fontsize)\n",
    "    plt.ylabel('True label', fontsize=fontsize)\n",
    "    plt.xlabel('Predicted label', fontsize=fontsize)\n",
    "    \n",
    "    plt.xticks(ticks=np.arange(0,len(labels),1), \n",
    "           labels=labels,\n",
    "           rotation = 90,\n",
    "           fontsize=fontsize_ticks)\n",
    "    \n",
    "    plt.yticks(ticks=np.arange(0,len(labels),1), \n",
    "       labels=labels,\n",
    "       rotation = 0,\n",
    "       fontsize=fontsize_ticks)\n",
    "    \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurenames[0] + '_' + method_prepared + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurenames[0], 'done')        \n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    # Visualize AUC-ROC curve\n",
    "    plot_roc(y_true=y_true, \n",
    "             y_probas=y_predicted_proba, \n",
    "             figsize=(8, 6))\n",
    "    \n",
    "    # Decoration\n",
    "    plt.title('', fontsize=fontsize)\n",
    "    plt.ylabel('True Positive Rate', fontsize=fontsize)\n",
    "    plt.xlabel('False Positive Rate', fontsize=fontsize)\n",
    "    \n",
    "    # Save figure option checker\n",
    "    if save == True:\n",
    "    \n",
    "        plt.savefig(path_to_save + figurenames[1] + '_' + method_prepared + '_' + str(date.today()) + '.png') # Save figure\n",
    "        \n",
    "        print('save figure:', figurenames[1], 'done')        \n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46972631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to write classification report\n",
    "def write_classification_report(y_test,\n",
    "                                y_predicted,\n",
    "                                is_network: bool,\n",
    "                                labels: list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to write classification report\n",
    "    1. Consider network-type model checker; if \"is_network\" == True: \n",
    "       reverse-transform labels => original format of integer-encoded labels\n",
    "    2. Write classification report\n",
    "    3. Return output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    # Network-type model checker\n",
    "    if is_network == True:\n",
    "        \n",
    "        # Reverse-transform labels => original format of integer-encoded labels\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        y_pred = np.argmax(y_predicted, axis=1)\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        y_true = y_test\n",
    "        y_pred = y_predicted\n",
    "    \n",
    "    # Write classification report\n",
    "    report = classification_report(y_true=y_true, \n",
    "                                   y_pred=y_pred, \n",
    "                                   target_names= labels)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d675ca",
   "metadata": {},
   "source": [
    "## 3. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18783206",
   "metadata": {},
   "source": [
    "### 3.1. Data Acquisition\n",
    "\n",
    "Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05253867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function to loading processed data\n",
    "## X train\n",
    "X_train = load_dataset(path_to_files=path_to_files,\n",
    "                       dataname=filename_X_train)\n",
    "\n",
    "## X test\n",
    "X_test = load_dataset(path_to_files=path_to_files,\n",
    "                      dataname=filename_X_test)\n",
    "\n",
    "## y train\n",
    "y_train = load_dataset(path_to_files=path_to_files,\n",
    "                       dataname=filename_y_train)\n",
    "\n",
    "## y test\n",
    "y_test = load_dataset(path_to_files=path_to_files,\n",
    "                      dataname=filename_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4079c3",
   "metadata": {},
   "source": [
    "### 3.2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc769304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network type estimator checker\n",
    "if is_network == False:\n",
    "    \n",
    "    # Convert format of y from one-hot -> interger\n",
    "    # Execute function to reverse-transform labels to integer-encoded labels\n",
    "    ## y train\n",
    "    y_train = reverse_transform_from_onehot(y_onehot=y_train)\n",
    "\n",
    "    ## y test\n",
    "    y_test = reverse_transform_from_onehot(y_onehot=y_test)\n",
    "    \n",
    "    # Reshape X to 2-D array for training model\n",
    "    ## Training X \n",
    "    X_train = X_train.ravel().reshape(X_train.shape[0], -1)\n",
    "\n",
    "    ## Testing X \n",
    "    X_test = X_test.ravel().reshape(X_test.shape[0], -1)\n",
    "    \n",
    "# else:\n",
    "    \n",
    "    # # Execute function to transform label using one-hot encoding\n",
    "    # ## y train\n",
    "    # y_train = transform_to_onehot(y=y_train,\n",
    "    #                               num_classes=num_classes)\n",
    "\n",
    "    # ## y test\n",
    "    # y_test = transform_to_onehot(y=y_test,\n",
    "    #                              num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97801bb",
   "metadata": {},
   "source": [
    "### 3.3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc3934",
   "metadata": {},
   "source": [
    "#### 3.3.a. Neural Network Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf65c00",
   "metadata": {},
   "source": [
    "Model construction (create new ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720aa34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True:\n",
    "\n",
    "    # CNN checker\n",
    "    if model_name == 'cnn_model':\n",
    "\n",
    "        # Execute function to construction CNN model architecture\n",
    "        model, callback = construct_cnn_model(X_train=X_train,\n",
    "                                              num_classes=num_classes,\n",
    "                                              model_name=model_name,\n",
    "                                              epochs=epochs,\n",
    "                                              verbose=verbose)\n",
    "\n",
    "    # MLP checker\n",
    "    elif model_name == 'mlp_model':\n",
    "\n",
    "        # Execute function to construction MLP model architecture\n",
    "        model, callback = construct_mlp_model(X_train=X_train,\n",
    "                                              num_classes=num_classes,\n",
    "                                              model_name=model_name,\n",
    "                                              epochs=epochs,\n",
    "                                          verbose=verbose)\n",
    "\n",
    "model.summary() # Summary the constructed model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a74d4",
   "metadata": {},
   "source": [
    "Load the save model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebea266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Execute function to load model from file\n",
    "# model = load_model(method_prepared=method_prepared,\n",
    "#                           is_network=is_network,\n",
    "#                           path_to_file=path_to_save,\n",
    "#                           filename=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19673df0",
   "metadata": {},
   "source": [
    "Visualize the network model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True:\n",
    "    \n",
    "    # CNN checker\n",
    "    if model_name == 'cnn_model':\n",
    "\n",
    "        # Define argument\n",
    "        figurename = 'cnn_model_architecture'\n",
    "        \n",
    "    # MLP checker\n",
    "    elif model_name == 'mlp_model':\n",
    "        \n",
    "        # Define metadata\n",
    "        figurename = 'mlp_model_architecture'\n",
    "\n",
    "    # Execute function to visualize model structure\n",
    "    viz_model(model=model,\n",
    "              method_prepared=method_prepared,\n",
    "              save=save,\n",
    "              figurename=figurename,\n",
    "              path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d8f4c7",
   "metadata": {},
   "source": [
    "Train network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True: \n",
    "\n",
    "    # Define hyperparameters\n",
    "    batch_size = X_train.shape[0] // 10 # Hyperparameter of sample amount to train per step\n",
    "\n",
    "    time_start = time.time() # Memory starting time\n",
    "    \n",
    "    # Fit model\n",
    "    history = model.fit(\n",
    "                        X_train, y_train, \n",
    "                        validation_data=(X_test, y_test),\n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        shuffle=True,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=verbose\n",
    "                        )\n",
    "    \n",
    "    time_end = time.time() # Memory ending time\n",
    "    \n",
    "    print('\\nTraining time usage =', time_end - time_start, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a803cd4d",
   "metadata": {},
   "source": [
    "#### 3.3.b. Non-neural Network Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53296096",
   "metadata": {},
   "source": [
    "Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-neural network model checker\n",
    "if is_network == False:\n",
    "\n",
    "    # Execute function to assign estimator according to the model name\n",
    "    estimator = prepare_estimator(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f13dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-neural network model checker\n",
    "if is_network == False:\n",
    "    \n",
    "    time_start = time.time() # Memory starting time\n",
    "    \n",
    "    n_jobs = 2 # Define parallele workers\n",
    "    \n",
    "    # Execute function to perform exhaustive search over specified parameter values for an estimator\n",
    "    model = optimize_parameter(X_train=X_train,\n",
    "                               y_train=y_train,\n",
    "                               estimator=estimator,\n",
    "                               n_jobs=n_jobs,\n",
    "                               param_distributions=param_distributions,\n",
    "                               verbose=verbose)\n",
    "    \n",
    "    time_end = time.time() # Memory ending time\n",
    "    \n",
    "    print('\\nOptimization time usage =', time_end - time_start, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1505ff",
   "metadata": {},
   "source": [
    "Inspect best hyperparameters from tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886609bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-neural network model checker\n",
    "if is_network == False:\n",
    "\n",
    "    pprint(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893767e2",
   "metadata": {},
   "source": [
    "Transfer optimal hyperparameters for training time usage measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430931eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-neural network model checker\n",
    "if is_network == False:\n",
    "    \n",
    "    model_measured = estimator # define estimator of the model\n",
    "    model_measured.set_params(**model.best_params_) # pass best parameters to test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8eb1a",
   "metadata": {},
   "source": [
    "Train non-network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-neural network model checker\n",
    "if is_network == False:\n",
    "    \n",
    "    time_start = time.time() # Memory starting time\n",
    "\n",
    "    # Fit model with optimal hyperparameters (this process is not neccesary)\n",
    "    model_measured.fit(X=X_train,\n",
    "                       y=y_train)\n",
    "\n",
    "    time_end = time.time() # Memory ending time\n",
    "    \n",
    "    print('\\nTraining time usage =', time_end - time_start, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce7b63",
   "metadata": {},
   "source": [
    "### 3.4. Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5405dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time() # Memory starting time\n",
    "\n",
    "y_predicted = model.predict(X_test) # predict labels\n",
    "\n",
    "# Non-neural network model checker\n",
    "if is_network == False:\n",
    "    \n",
    "    y_predicted_proba = model.predict_proba(X_test) # predict label as probability for AUC-ROC curves\n",
    "    \n",
    "time_end = time.time() # Memory ending time\n",
    "\n",
    "print('\\nPrediction time usage =', time_end - time_start, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69305de6",
   "metadata": {},
   "source": [
    "### 3.5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35ea02",
   "metadata": {},
   "source": [
    "#### 3.5.1. Neural Network Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bf33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True: \n",
    "    \n",
    "    # Evaluate the trained model\n",
    "    evaluation = model.evaluate(x=X_test,\n",
    "                                y=y_test,\n",
    "                                verbose=0)\n",
    "\n",
    "    print('Model Evaluation:')\n",
    "    print('      Loss                    =', evaluation[0])\n",
    "    print('      Classification Accuracy =', evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735dda4",
   "metadata": {},
   "source": [
    "#### 3.5.2. Model Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True: \n",
    "    \n",
    "    # Define metadata\n",
    "    figurenames = [model_name_figure + ' Model Accuracy', model_name_figure + ' Model Loss']\n",
    "\n",
    "    # Execute function to visualize model performance summary\n",
    "    viz_error(history=history,\n",
    "              method_prepared=method_prepared,\n",
    "              save=save,\n",
    "              path_to_save=path_to_save,\n",
    "              figurenames=figurenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276c1f0",
   "metadata": {},
   "source": [
    "#### 3.5.3 Confusion Matrix and AUC-ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a9766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True:\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=\"categorical_crossentropy\", \n",
    "                         optimizer=\"adam\", \n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "    # Evaluate the loaded model\n",
    "    evaluation = model.evaluate(x=X_test, \n",
    "                          y=y_test, \n",
    "                          verbose=0)\n",
    "\n",
    "    print('Model Evaluation:')\n",
    "    print('      Loss                    =', evaluation[0])\n",
    "    print('      Classification Accuracy =', evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62164db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metadata\n",
    "figurenames = [model_name_figure + ' Model Confusion Matrix', model_name_figure + ' Model AUC-ROC curves']\n",
    "\n",
    "# Neural network model checker\n",
    "if is_network == True:\n",
    "    \n",
    "    y_predicted_proba = y_predicted # Set prediction to probalistic prediction, since it is the same\n",
    "\n",
    "# Execute function to visualize confusion matrix and AUC-ROC curve of the model\n",
    "viz_confusion_matrix_and_aucroc(y_test=y_test,\n",
    "                                y_predicted=y_predicted,\n",
    "                                y_predicted_proba=y_predicted_proba,\n",
    "                                cmap=cmap,\n",
    "                                labels=labels,\n",
    "                                num_classes=num_classes,\n",
    "                                method_prepared=method_prepared,\n",
    "                                is_network=is_network,\n",
    "                                save=save,\n",
    "                                path_to_save=path_to_save,\n",
    "                                figurenames=figurenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ccde4",
   "metadata": {},
   "source": [
    "#### 3.5.4. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function to write classification report\n",
    "report = write_classification_report(y_test=y_test,\n",
    "                                     y_predicted=y_predicted,\n",
    "                                     is_network=is_network,\n",
    "                                     labels=labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de06c24",
   "metadata": {},
   "source": [
    "## 4. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function to save model to file\n",
    "save_model(model=model, \n",
    "           method_prepared=method_prepared,\n",
    "           is_network=is_network,\n",
    "           path_to_save=path_to_save,\n",
    "           filename=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850575b",
   "metadata": {},
   "source": [
    "## 5. Saved Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c4c8b",
   "metadata": {},
   "source": [
    "### 5.1. Saved Model Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function to load model from file\n",
    "loaded_model = load_model(method_prepared=method_prepared,\n",
    "                          is_network=is_network,\n",
    "                          path_to_file=path_to_save,\n",
    "                          filename=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8145b",
   "metadata": {},
   "source": [
    "### 5.2. Saved Neural Network Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51834827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model checker\n",
    "if is_network == True:\n",
    "\n",
    "    # Compile model\n",
    "    loaded_model.compile(loss=\"categorical_crossentropy\", \n",
    "                         optimizer=\"adam\", \n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "    # Evaluate the loaded model\n",
    "    loaded_model.evaluate(x=X_test, \n",
    "                          y=y_test, \n",
    "                          verbose=0)\n",
    "\n",
    "    print('Model Evaluation:')\n",
    "    print('      Loss                    =', evaluation[0])\n",
    "    print('      Classification Accuracy =', evaluation[1])\n",
    "\n",
    "    # Prediction using loaded model\n",
    "    y_predicted_loaded_model = loaded_model.predict(x=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd33d4",
   "metadata": {},
   "source": [
    "### 5.3. Saved Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae42163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using loaded model\n",
    "y_predicted_loaded_model = loaded_model.predict(X_test)\n",
    "\n",
    "# Execute function to write classification report\n",
    "report_loaded_model = write_classification_report(y_test=y_test,\n",
    "                                                  y_predicted=y_predicted_loaded_model,\n",
    "                                                  is_network=is_network,\n",
    "                                                  labels=labels)\n",
    "\n",
    "print(report_loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534c860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
